{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is dedicated to second chapter. Exercises itself could be found at page 127."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import tarfile \n",
    "import urllib\n",
    "import numpy as np\n",
    " \n",
    "    \n",
    "HOUSING_PATH = \"C:\\margo\\ML\\Geron\\git_example\\handson-ml2\\datasets\\housing\"\n",
    "    \n",
    "def load_housing_data(housing_path=HOUSING_PATH): \n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")     \n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "housing = load_housing_data(HOUSING_PATH)\n",
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_set(data, test_ratio):\n",
    "        shuffled_indices = np.random.permutation(len(data))\n",
    "        test_set_size = int(len(data) * test_ratio)\n",
    "        test_indices = shuffled_indices[:test_set_size]\n",
    "        train_indices = shuffled_indices[test_set_size:]     \n",
    "        return data.iloc[train_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = split_train_set(housing, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set lenght is:16512;\n",
      "test set lenght is: 4128\n"
     ]
    }
   ],
   "source": [
    "print(\"train set lenght is:\" + str(len(train_set)) + \";\\ntest set lenght is: \" +str(len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit \n",
    "\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6.0, 7.5, 9.0, np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42) \n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):     \n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "    \n",
    "\n",
    "for set_ in (strat_train_set, strat_test_set):     \n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s create new attributes, that will be a bit more informative for dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"] / housing[\"households\"]\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"] / housing[\"total_rooms\"] \n",
    "housing[\"population_per_household\"]=housing[\"population\"] / housing[\"households\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop(\"median_house_value\", axis=1) \n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "#imputer = SimpleImputer(strategy=\"median\")\n",
    "#imputer.fit(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    " \n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):     \n",
    "    def __init__(self, add_bedrooms_per_room = True): # no * args or ** kargs\n",
    "         self.add_bedrooms_per_room = add_bedrooms_per_room     \n",
    "    def fit(self, X, y=None):         \n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:             \n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room] \n",
    " \n",
    "        else:             \n",
    "            return np.c_[X, rooms_per_household, population_per_household] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just created transformer that will help as to get data prepared for training. As the last preparation step we ought to create a Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "#housing_extra_attribs = attr_adder.transform(housing.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler \n",
    " \n",
    "num_pipeline = Pipeline([         \n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder', CombinedAttributesAdder()), \n",
    "        ('std_scaler', StandardScaler()),     \n",
    "    ]) \n",
    " \n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "    \n",
    "num_attribs = list(housing_num) \n",
    "cat_attribs = [\"ocean_proximity\"] \n",
    " \n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs),     \n",
    "    ]) \n",
    " \n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    " \n",
    "lin_reg = LinearRegression() \n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [ 85567.3451932  471965.3878167  151916.14768674 186477.93483214\n",
      " 244358.19381986]\n"
     ]
    }
   ],
   "source": [
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data) \n",
    "print(\"Predictions:\", lin_reg.predict(some_data_prepared)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cells that lying above were taken from the book itself, now let`s take a look on exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\n",
    "Try a Support Vector Machine regressor (sklearn.svm.SVR) with various hyperparameters, such as kernel=\"linear\" (with various values for the C hyperparameter) or kernel=\"rbf\" (with various values for the C and gamma hyperparameters). Don’t worry about what these hyperparameters mean for now. How does the best SVR predictor perform? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71237.10538307506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def SvrBuildUp(housing_prepared, housing_labels, kernel_type, C_param, gamma_param='auto', epsilon_param=.1):\n",
    "    svr = SVR(kernel=kernel_type, C=C_param, gamma=gamma_param, epsilon=epsilon_param)\n",
    "    svr.fit(housing_prepared, housing_labels)\n",
    "    svr_housing_predictions = svr.predict(housing_prepared)\n",
    "    svr_mse = mean_squared_error(housing_labels, svr_housing_predictions) \n",
    "    return np.sqrt(svr_mse) \n",
    "\n",
    "svr_lin_rmse = SvrBuildUp(housing_prepared, housing_labels, 'linear', 100, 'auto')\n",
    "print(svr_lin_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118357.29776637343"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "svr = SVR()\n",
    "svr.fit(housing_prepared, housing_labels)\n",
    "svr_housing_predictions = svr.predict(housing_prepared)\n",
    "svr_mse = mean_squared_error(housing_labels, svr_housing_predictions) \n",
    "svr_rmse = np.sqrt(svr_mse) \n",
    "svr_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95429.8862063893"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsvr_rbf_rmse = SvrBuildUp(housing_prepared, housing_labels, 'rbf', 100, 0.1, .3)\n",
    "nsvr_rbf_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71237.10538307506"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsvr_lin_rmse = SvrBuildUp(housing_prepared, housing_labels, 'linear', 100, 'auto')\n",
    "nsvr_lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75031.18355631913"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_poly = SVR(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1,\n",
    "               coef0=1)\n",
    "svr_poly.fit(housing_prepared, housing_labels)\n",
    "svr_poly_housing_predictions = svr_poly.predict(housing_prepared)\n",
    "svr_poly_mse = mean_squared_error(housing_labels, svr_poly_housing_predictions) \n",
    "svr_poly_rmse = np.sqrt(svr_poly_mse) \n",
    "svr_poly_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116938.01912668717"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsvr_poly_rmse = SvrBuildUp(housing_prepared, housing_labels, 'poly', 10, 'auto')\n",
    "nsvr_poly_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81913.70157811412"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnsvr_lin_rmse = SvrBuildUp(housing_prepared, housing_labels, 'linear', 10, 'auto')\n",
    "nnsvr_lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70278.49017554823"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsvr_lin_rmse = SvrBuildUp(housing_prepared, housing_labels, 'linear', 900, 'auto')\n",
    "nsvr_lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. Try replacing GridSearchCV with RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV \n",
    " \n",
    "# param_grid = [     {'C': [10, 100, 500], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
    "#               { 'C': [80, 100, 130], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma':['scale', 'auto'], \n",
    "#                'degree':[1, 2, 4, 8, 10], 'epsilon':[0.01, 0.05 ,.1, .2, .5, .8,]}, ]\n",
    "#                #'coef0' :[0, 0.5, 1, 2]},   ]\n",
    "\n",
    "\n",
    "# svr_search = SVR()\n",
    " \n",
    "# grid_search = GridSearchCV(svr_search, param_grid, cv=5,\n",
    "#                            scoring='neg_mean_squared_error',\n",
    "#                            return_train_score=True) \n",
    "\n",
    "# #SVR().get_params().keys()\n",
    "# grid_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVR(),\n",
       "             param_grid={'C': [100, 500, 1000],\n",
       "                         'kernel': ['linear', 'rbf', 'sigmoid']},\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    " \n",
    "param_grid = {'C': [ 100, 500, 1000], 'kernel': ['linear',  'rbf', 'sigmoid'] }\n",
    "               #'coef0' :[0, 0.5, 1, 2]},   ]\n",
    "\n",
    "\n",
    "svr_search = SVR()\n",
    " \n",
    "grid_search = GridSearchCV(svr_search, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True, refit=True) \n",
    "\n",
    "\n",
    "grid_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] C=11, kernel=poly ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................ C=11, kernel=poly, total=   6.6s\n",
      "[CV] C=11, kernel=poly ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................ C=11, kernel=poly, total=   6.2s\n",
      "[CV] C=11, kernel=poly ...............................................\n",
      "[CV] ................................ C=11, kernel=poly, total=   6.5s\n",
      "[CV] C=11, kernel=poly ...............................................\n",
      "[CV] ................................ C=11, kernel=poly, total=   6.4s\n",
      "[CV] C=11, kernel=poly ...............................................\n",
      "[CV] ................................ C=11, kernel=poly, total=   6.4s\n",
      "[CV] C=15, kernel=rbf ................................................\n",
      "[CV] ................................. C=15, kernel=rbf, total=   9.1s\n",
      "[CV] C=15, kernel=rbf ................................................\n",
      "[CV] ................................. C=15, kernel=rbf, total=   9.0s\n",
      "[CV] C=15, kernel=rbf ................................................\n",
      "[CV] ................................. C=15, kernel=rbf, total=   9.0s\n",
      "[CV] C=15, kernel=rbf ................................................\n",
      "[CV] ................................. C=15, kernel=rbf, total=   9.0s\n",
      "[CV] C=15, kernel=rbf ................................................\n",
      "[CV] ................................. C=15, kernel=rbf, total=   8.9s\n",
      "[CV] C=42, kernel=sigmoid ............................................\n",
      "[CV] ............................. C=42, kernel=sigmoid, total=  10.5s\n",
      "[CV] C=42, kernel=sigmoid ............................................\n",
      "[CV] ............................. C=42, kernel=sigmoid, total=  10.5s\n",
      "[CV] C=42, kernel=sigmoid ............................................\n",
      "[CV] ............................. C=42, kernel=sigmoid, total=  10.6s\n",
      "[CV] C=42, kernel=sigmoid ............................................\n",
      "[CV] ............................. C=42, kernel=sigmoid, total=  10.5s\n",
      "[CV] C=42, kernel=sigmoid ............................................\n",
      "[CV] ............................. C=42, kernel=sigmoid, total=  10.5s\n",
      "[CV] C=97, kernel=linear .............................................\n",
      "[CV] .............................. C=97, kernel=linear, total=   5.3s\n",
      "[CV] C=97, kernel=linear .............................................\n",
      "[CV] .............................. C=97, kernel=linear, total=   5.2s\n",
      "[CV] C=97, kernel=linear .............................................\n",
      "[CV] .............................. C=97, kernel=linear, total=   6.0s\n",
      "[CV] C=97, kernel=linear .............................................\n",
      "[CV] .............................. C=97, kernel=linear, total=   5.3s\n",
      "[CV] C=97, kernel=linear .............................................\n",
      "[CV] .............................. C=97, kernel=linear, total=   5.4s\n",
      "[CV] C=189, kernel=sigmoid ...........................................\n",
      "[CV] ............................ C=189, kernel=sigmoid, total=  10.8s\n",
      "[CV] C=189, kernel=sigmoid ...........................................\n",
      "[CV] ............................ C=189, kernel=sigmoid, total=  12.1s\n",
      "[CV] C=189, kernel=sigmoid ...........................................\n",
      "[CV] ............................ C=189, kernel=sigmoid, total=  11.8s\n",
      "[CV] C=189, kernel=sigmoid ...........................................\n",
      "[CV] ............................ C=189, kernel=sigmoid, total=  12.0s\n",
      "[CV] C=189, kernel=sigmoid ...........................................\n",
      "[CV] ............................ C=189, kernel=sigmoid, total=  11.2s\n",
      "[CV] C=22, kernel=poly ...............................................\n",
      "[CV] ................................ C=22, kernel=poly, total=   7.5s\n",
      "[CV] C=22, kernel=poly ...............................................\n",
      "[CV] ................................ C=22, kernel=poly, total=   7.2s\n",
      "[CV] C=22, kernel=poly ...............................................\n",
      "[CV] ................................ C=22, kernel=poly, total=   7.2s\n",
      "[CV] C=22, kernel=poly ...............................................\n",
      "[CV] ................................ C=22, kernel=poly, total=   7.3s\n",
      "[CV] C=22, kernel=poly ...............................................\n",
      "[CV] ................................ C=22, kernel=poly, total=   7.6s\n",
      "[CV] C=18, kernel=linear .............................................\n",
      "[CV] .............................. C=18, kernel=linear, total=   6.2s\n",
      "[CV] C=18, kernel=linear .............................................\n",
      "[CV] .............................. C=18, kernel=linear, total=   6.4s\n",
      "[CV] C=18, kernel=linear .............................................\n",
      "[CV] .............................. C=18, kernel=linear, total=   6.5s\n",
      "[CV] C=18, kernel=linear .............................................\n",
      "[CV] .............................. C=18, kernel=linear, total=   6.4s\n",
      "[CV] C=18, kernel=linear .............................................\n",
      "[CV] .............................. C=18, kernel=linear, total=   6.2s\n",
      "[CV] C=104, kernel=rbf ...............................................\n",
      "[CV] ................................ C=104, kernel=rbf, total=  10.0s\n",
      "[CV] C=104, kernel=rbf ...............................................\n",
      "[CV] ................................ C=104, kernel=rbf, total=   9.8s\n",
      "[CV] C=104, kernel=rbf ...............................................\n",
      "[CV] ................................ C=104, kernel=rbf, total=   9.7s\n",
      "[CV] C=104, kernel=rbf ...............................................\n",
      "[CV] ................................ C=104, kernel=rbf, total=  10.2s\n",
      "[CV] C=104, kernel=rbf ...............................................\n",
      "[CV] ................................ C=104, kernel=rbf, total=  10.1s\n",
      "[CV] C=181, kernel=linear ............................................\n",
      "[CV] ............................. C=181, kernel=linear, total=   6.0s\n",
      "[CV] C=181, kernel=linear ............................................\n",
      "[CV] ............................. C=181, kernel=linear, total=   6.3s\n",
      "[CV] C=181, kernel=linear ............................................\n",
      "[CV] ............................. C=181, kernel=linear, total=   6.8s\n",
      "[CV] C=181, kernel=linear ............................................\n",
      "[CV] ............................. C=181, kernel=linear, total=   6.0s\n",
      "[CV] C=181, kernel=linear ............................................\n",
      "[CV] ............................. C=181, kernel=linear, total=   6.4s\n",
      "[CV] C=17, kernel=poly ...............................................\n",
      "[CV] ................................ C=17, kernel=poly, total=   7.5s\n",
      "[CV] C=17, kernel=poly ...............................................\n",
      "[CV] ................................ C=17, kernel=poly, total=   7.3s\n",
      "[CV] C=17, kernel=poly ...............................................\n",
      "[CV] ................................ C=17, kernel=poly, total=   7.5s\n",
      "[CV] C=17, kernel=poly ...............................................\n",
      "[CV] ................................ C=17, kernel=poly, total=   7.2s\n",
      "[CV] C=17, kernel=poly ...............................................\n",
      "[CV] ................................ C=17, kernel=poly, total=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  9.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=SVR(),\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000016A84A6EBB0>,\n",
       "                                        'kernel': ['linear', 'poly', 'rbf',\n",
       "                                                   'sigmoid']},\n",
       "                   random_state=28, return_train_score=True,\n",
       "                   scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_rand = {'C': randint(10, 200), 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "\n",
    "#randint(1, 9)\n",
    "svr_rand = SVR()\n",
    " \n",
    "    \n",
    "rand_search = RandomizedSearchCV(svr_rand, param_rand,\n",
    "                                n_iter=10, cv=5, scoring='neg_mean_squared_error',\n",
    "                                verbose=2, random_state=28, return_train_score=True)    \n",
    "\n",
    "\n",
    "#SVR().get_params().keys()\n",
    "rand_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Try adding a transformer in the preparation pipeline to select only the\n",
    "most important attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def GetFeatureImportancesRandomForest():\n",
    "    housing_prepared = full_pipeline.fit_transform(housing)\n",
    "\n",
    "    param_grid = [ {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "        {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]}, ]\n",
    "\n",
    "    forest_reg = RandomForestRegressor(random_state=42)\n",
    "    grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                               scoring='neg_mean_squared_error',\n",
    "                               return_train_score=True)\n",
    "    grid_search.fit(housing_prepared, housing_labels)\n",
    "\n",
    "    feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "    print(feature_importances)\n",
    "    return feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we don't have feature importances scale, we create it within Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def indices_of_top_k(arr, k):\n",
    "    return np.sort(np.argpartition(np.array(arr), -k)[-k:])\n",
    "\n",
    "class TopFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,  k, feature_importances = None ):\n",
    "        if feature_importances:\n",
    "            self.feature_importances = feature_importances\n",
    "        else:\n",
    "            self.feature_importances = GetFeatureImportancesRandomForest()\n",
    "        self.k = k\n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_indices_ = indices_of_top_k(self.feature_importances, self.k)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[:, self.feature_indices_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 5\n",
    "# top_k_feature_indices = indices_of_top_k(feature_importances, k)\n",
    "# top_k_feature_indices\n",
    "# prepare_select_and_predict_pipeline.fit(housing, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Try creating a single pipeline that does the full data preparation plus\n",
    "the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.10605432e-02 6.44287813e-02 4.54178421e-02 1.77443793e-02\n",
      " 1.64922497e-02 1.70322309e-02 1.57611437e-02 3.29082991e-01\n",
      " 5.02566854e-02 1.07451736e-01 9.50849568e-02 1.19604716e-02\n",
      " 1.48724641e-01 8.53589015e-05 5.14727060e-03 4.26871818e-03]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.89522651,  0.00614618,  1.        ],\n",
       "       [ 3.81608801,  0.02702276,  0.        ],\n",
       "       [-0.52597384, -0.07544594,  1.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 3\n",
    "preparation_and_feature_selection_pipeline = Pipeline([\n",
    "    ('preparation', full_pipeline),\n",
    "    ('feature_selection', TopFeatureSelector(k, None))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "housing_prepared_top_k_features = preparation_and_feature_selection_pipeline.fit_transform(housing)\n",
    "\n",
    "housing_prepared_top_k_features[0:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.10605432e-02 6.44287813e-02 4.54178421e-02 1.77443793e-02\n",
      " 1.64922497e-02 1.70322309e-02 1.57611437e-02 3.29082991e-01\n",
      " 5.02566854e-02 1.07451736e-01 9.50849568e-02 1.19604716e-02\n",
      " 1.48724641e-01 8.53589015e-05 5.14727060e-03 4.26871818e-03]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preparation',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('attribs_adder',\n",
       "                                                                   CombinedAttributesAdder()),\n",
       "                                                                  ('std_scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['longitude', 'latitude',\n",
       "                                                   'housing_median_age',\n",
       "                                                   'total_rooms',\n",
       "                                                   'total_bedrooms',\n",
       "                                                   'population', 'households',\n",
       "                                                   'median_income']),\n",
       "                                                 ('cat', OneHotEncoder(...\n",
       "                ('feature_selection',\n",
       "                 TopFeatureSelector(feature_importances=array([7.10605432e-02, 6.44287813e-02, 4.54178421e-02, 1.77443793e-02,\n",
       "       1.64922497e-02, 1.70322309e-02, 1.57611437e-02, 3.29082991e-01,\n",
       "       5.02566854e-02, 1.07451736e-01, 9.50849568e-02, 1.19604716e-02,\n",
       "       1.48724641e-01, 8.53589015e-05, 5.14727060e-03, 4.26871818e-03]),\n",
       "                                    k=5)),\n",
       "                ('svm_reg', SVR(C=1000, kernel='linear'))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "prepare_select_and_predict_pipeline = Pipeline([\n",
    "    ('preparation', full_pipeline),\n",
    "    ('feature_selection', TopFeatureSelector(k)),\n",
    "    ('svm_reg', SVR(**grid_search.best_params_))\n",
    "])\n",
    "\n",
    "\n",
    "prepare_select_and_predict_pipeline.fit(housing, housing_labels)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
