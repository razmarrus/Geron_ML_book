{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Regression MLP Using the Sequential API\n",
    "Let’s switch to the California housing problem and tackle it using a\n",
    "regression neural network.   \n",
    "After loading the data, we split it into a training set, a\n",
    "validation set, and a test set, and we scale all the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train_full, y_train_full)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.9155 - val_loss: 1.4037\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.6986 - val_loss: 0.4952\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4925 - val_loss: 0.4442\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4689 - val_loss: 0.4296\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4587 - val_loss: 0.4873\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4517 - val_loss: 0.4203\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4407 - val_loss: 0.4117\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4351 - val_loss: 0.4112\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4293 - val_loss: 0.4061\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4256 - val_loss: 0.4069\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4666 - val_loss: 0.4169\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4297 - val_loss: 0.3961\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4186 - val_loss: 0.3921\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4143 - val_loss: 0.4007\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4107 - val_loss: 0.3826\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4047 - val_loss: 0.3814\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4006 - val_loss: 0.4411\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4038 - val_loss: 0.3764\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3944 - val_loss: 0.3702\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3926 - val_loss: 0.3695\n",
      "5160/5160 [==============================] - 0s 22us/sample - loss: 0.3759\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Dense(30, activation=\"relu\",\n",
    "input_shape=X_train.shape[1:]),\n",
    "keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the Sequential API is quite easy to use. However, although\n",
    "Sequential models are extremely common, it is sometimes useful to\n",
    "build neural networks with more complex topologies, or with multiple\n",
    "inputs or outputs. For this purpose, Keras offers the Functional API.\n",
    "\n",
    "\n",
    "# Building Complex Models Using the Functional API\n",
    "One example of a nonsequential neural network is a Wide & Deep neural\n",
    "network. This neural network architecture was introduced in a 2016 paper\n",
    "by Heng-Tze Cheng et al. It connects all or part of the inputs directly to\n",
    "the output layer,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s go through each line of this code:\n",
    "* First, we need to create an Input object. This is a specification\n",
    "of the kind of input the model will get, including its shape and\n",
    "dtype. A model may actually have multiple inputs, as we will see\n",
    "shortly.\n",
    "* Next, we create a Dense layer with 30 neurons, using the ReLU\n",
    "activation function. As soon as it is created, notice that we call it\n",
    "like a function, passing it the input. This is why this is called the\n",
    "Functional API. Note that we are just telling Keras how it should\n",
    "connect the layers together; no actual data is being processed yet.\n",
    "* We then create a second hidden layer, and again we use it as a\n",
    "function. Note that we pass it the output of the first hidden layer.\n",
    "* Next, we create a Concatenate layer, and once again we\n",
    "immediately use it like a function, to concatenate the input and\n",
    "the output of the second hidden layer. You may prefer the\n",
    "keras.layers.concatenate() function, which creates a\n",
    "Concatenate layer and immediately calls it with the given inputs.\n",
    "* Then we create the output layer, with a single neuron and no\n",
    "activation function, and we call it like a function, passing it the\n",
    "result of the concatenation.\n",
    "\n",
    "Lastly, we create a Keras Model, specifying which inputs and\n",
    "outputs to use.  \n",
    "If you want to send a subset of the features through the wide path\n",
    "and a different subset (possibly overlapping) through the deep path? In this case, one solution is to use multiple inputs. For\n",
    "example, suppose we want to send five features through the wide path\n",
    "(features 0 to 4), and six features through the deep path (features 2 to 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 2.3705 - val_loss: 1.0433\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.9506 - val_loss: 0.7838\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.7966 - val_loss: 0.6965\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.7290 - val_loss: 0.6473\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.6868 - val_loss: 0.6132\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.6558 - val_loss: 0.5892\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.6318 - val_loss: 0.5684\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.6120 - val_loss: 0.5537\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.5954 - val_loss: 0.5387\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.5813 - val_loss: 0.5277\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.5694 - val_loss: 0.5175\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.5582 - val_loss: 0.5086\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.5493 - val_loss: 0.5004\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.5411 - val_loss: 0.4933\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.5332 - val_loss: 0.4879\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.5255 - val_loss: 0.4818\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.5190 - val_loss: 0.4758\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.5133 - val_loss: 0.4754\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.5085 - val_loss: 0.4709\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.5031 - val_loss: 0.4634\n",
      "5160/5160 [==============================] - 0s 22us/sample - loss: 0.4792\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model we want to have multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output,\n",
    "aux_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each output will need its own loss function. Therefore, when we compile\n",
    "the model, we should pass a list of losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1],\n",
    "optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 100us/sample - loss: 0.8309 - main_output_loss: 0.7427 - aux_output_loss: 1.6220 - val_loss: 0.5255 - val_main_output_loss: 0.4762 - val_aux_output_loss: 0.9686\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.5842 - main_output_loss: 0.5432 - aux_output_loss: 0.9522 - val_loss: 0.4944 - val_main_output_loss: 0.4513 - val_aux_output_loss: 0.8817\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.5264 - main_output_loss: 0.4915 - aux_output_loss: 0.8388 - val_loss: 0.4703 - val_main_output_loss: 0.4364 - val_aux_output_loss: 0.7745\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4927 - main_output_loss: 0.4628 - aux_output_loss: 0.7608 - val_loss: 0.4535 - val_main_output_loss: 0.4255 - val_aux_output_loss: 0.7053\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.6069 - main_output_loss: 0.5899 - aux_output_loss: 0.7578 - val_loss: 0.4672 - val_main_output_loss: 0.4416 - val_aux_output_loss: 0.6964\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.5278 - main_output_loss: 0.5102 - aux_output_loss: 0.6882 - val_loss: 0.4488 - val_main_output_loss: 0.4277 - val_aux_output_loss: 0.6377\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4670 - main_output_loss: 0.4469 - aux_output_loss: 0.6468 - val_loss: 0.4276 - val_main_output_loss: 0.4070 - val_aux_output_loss: 0.6113\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.4661 - main_output_loss: 0.4483 - aux_output_loss: 0.6244 - val_loss: 0.4145 - val_main_output_loss: 0.3951 - val_aux_output_loss: 0.5876\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.4616 - main_output_loss: 0.4449 - aux_output_loss: 0.6107 - val_loss: 0.4366 - val_main_output_loss: 0.4192 - val_aux_output_loss: 0.5922\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4445 - main_output_loss: 0.4277 - aux_output_loss: 0.5966 - val_loss: 0.3994 - val_main_output_loss: 0.3819 - val_aux_output_loss: 0.5557\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.4355 - main_output_loss: 0.4190 - aux_output_loss: 0.5859 - val_loss: 0.3907 - val_main_output_loss: 0.3731 - val_aux_output_loss: 0.5475\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4234 - main_output_loss: 0.4072 - aux_output_loss: 0.5713 - val_loss: 0.4047 - val_main_output_loss: 0.3891 - val_aux_output_loss: 0.5441\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.4151 - main_output_loss: 0.3995 - aux_output_loss: 0.5569 - val_loss: 0.3806 - val_main_output_loss: 0.3644 - val_aux_output_loss: 0.5253\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.4074 - main_output_loss: 0.3923 - aux_output_loss: 0.5476 - val_loss: 0.3854 - val_main_output_loss: 0.3699 - val_aux_output_loss: 0.5241\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4041 - main_output_loss: 0.3892 - aux_output_loss: 0.5368 - val_loss: 0.3680 - val_main_output_loss: 0.3528 - val_aux_output_loss: 0.5039\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3964 - main_output_loss: 0.3816 - aux_output_loss: 0.5296 - val_loss: 0.3723 - val_main_output_loss: 0.3576 - val_aux_output_loss: 0.5037\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3930 - main_output_loss: 0.3789 - aux_output_loss: 0.5197 - val_loss: 0.3701 - val_main_output_loss: 0.3562 - val_aux_output_loss: 0.4943\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3863 - main_output_loss: 0.3725 - aux_output_loss: 0.5110 - val_loss: 0.3574 - val_main_output_loss: 0.3435 - val_aux_output_loss: 0.4820\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3836 - main_output_loss: 0.3704 - aux_output_loss: 0.5042 - val_loss: 0.3738 - val_main_output_loss: 0.3610 - val_aux_output_loss: 0.4883\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3803 - main_output_loss: 0.3674 - aux_output_loss: 0.4963 - val_loss: 0.3552 - val_main_output_loss: 0.3419 - val_aux_output_loss: 0.4739\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "[X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 26us/sample - loss: 0.3582 - main_output_loss: 0.3440 - aux_output_loss: 0.4765\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "[X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Using the Subclassing API to Build Dynamic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some models involve loops, varying shapes,\n",
    "conditional branching, and other dynamic behaviors. For such cases, or\n",
    "simply if you prefer a more imperative programming style, the\n",
    "Subclassing API is for you.  \n",
    "Simply subclass the Model class, create the layers you need in the\n",
    "constructor, and use them to perform the computations you want in the\n",
    "call() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # handles standard args (e.g., name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Restoring a Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the Sequential API or the Functional API, saving a trained\n",
    "Keras model is as simple as it gets:\n",
    "```python\n",
    "model = keras.layers.Sequential([...]) # or keras.Model([...])\n",
    "model.compile([...])\n",
    "model.fit([...])\n",
    "model.save(\"my_keras_model.h5\")\n",
    "```\n",
    " Loading the model is just as easy:\n",
    "```python\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Callbacks\n",
    "The fit() method accepts a callbacks argument that lets you specify a\n",
    "list of objects that Keras will call at the start and end of training, at the\n",
    "start and end of each epoch, and even before and after processing each\n",
    "batch. \n",
    "```python\n",
    "[...] # build and compile the model\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=\n",
    "[checkpoint_cb])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Using TensorBoard for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
    "        data = (np.random.randn(100) + 2) * step / 100 # some random data\n",
    "        tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
    "        images = np.random.rand(2, 32, 32, 3) # random 32×32 RGB images\n",
    "        tf.summary.image(\"my_images\", images * step / 1000, step=step)\n",
    "        texts = [\"The step is \" + str(step), \"Its square is \" +\n",
    "        str(step**2)]\n",
    "        tf.summary.text(\"my_text\", texts, step=step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi *\n",
    "        step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fine-Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3,\n",
    "input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 1.4926 - val_loss: 0.7664\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.7500 - val_loss: 0.6528\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.6538 - val_loss: 0.5789\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.5938 - val_loss: 0.5355\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.5503 - val_loss: 0.5027\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.5218 - val_loss: 0.4770\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.5012 - val_loss: 0.4609\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4875 - val_loss: 0.4520\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.4769 - val_loss: 0.4458\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4687 - val_loss: 0.4404\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4620 - val_loss: 0.4333\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.4572 - val_loss: 0.4292\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4519 - val_loss: 0.4245\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4470 - val_loss: 0.4200\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4422 - val_loss: 0.4157\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4380 - val_loss: 0.4147\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.4349 - val_loss: 0.4117\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4317 - val_loss: 0.4075\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4290 - val_loss: 0.4055\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4260 - val_loss: 0.4028\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4232 - val_loss: 0.4005\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4213 - val_loss: 0.4030\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4187 - val_loss: 0.3980\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4178 - val_loss: 0.3993\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4148 - val_loss: 0.3956\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4142 - val_loss: 0.3967\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4140 - val_loss: 0.3928\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4105 - val_loss: 0.3929\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4114 - val_loss: 0.3925\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4075 - val_loss: 0.3902\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4057 - val_loss: 0.3865\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4043 - val_loss: 0.3918\n",
      "Epoch 33/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4032 - val_loss: 0.3864\n",
      "Epoch 34/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4015 - val_loss: 0.3848\n",
      "Epoch 35/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4011 - val_loss: 0.3842\n",
      "Epoch 36/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4001 - val_loss: 0.3839\n",
      "Epoch 37/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4039 - val_loss: 0.3898\n",
      "Epoch 38/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4123 - val_loss: 0.3818\n",
      "Epoch 39/100\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3982 - val_loss: 0.3790\n",
      "Epoch 40/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3963 - val_loss: 0.3794\n",
      "Epoch 41/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3972 - val_loss: 0.3814\n",
      "Epoch 42/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4015 - val_loss: 0.3775\n",
      "Epoch 43/100\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3938 - val_loss: 0.3756\n",
      "Epoch 44/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3956 - val_loss: 0.3738\n",
      "Epoch 45/100\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3909 - val_loss: 0.3754\n",
      "Epoch 46/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3920 - val_loss: 0.3742\n",
      "Epoch 47/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3894 - val_loss: 0.3738\n",
      "Epoch 48/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3895 - val_loss: 0.3718\n",
      "Epoch 49/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3885 - val_loss: 0.3701\n",
      "Epoch 50/100\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3875 - val_loss: 0.3705\n",
      "Epoch 51/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3865 - val_loss: 0.3711\n",
      "Epoch 52/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3863 - val_loss: 0.3717\n",
      "Epoch 53/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3870 - val_loss: 0.3703\n",
      "Epoch 54/100\n",
      "11610/11610 [==============================] - ETA: 0s - loss: 0.385 - 0s 35us/sample - loss: 0.3861 - val_loss: 0.3673\n",
      "Epoch 55/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3843 - val_loss: 0.3677\n",
      "Epoch 56/100\n",
      "11610/11610 [==============================] - ETA: 0s - loss: 0.382 - 1s 48us/sample - loss: 0.3842 - val_loss: 0.3672\n",
      "Epoch 57/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3828 - val_loss: 0.3678\n",
      "Epoch 58/100\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3827 - val_loss: 0.3660\n",
      "Epoch 59/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3820 - val_loss: 0.3674\n",
      "Epoch 60/100\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3849 - val_loss: 0.3646\n",
      "Epoch 61/100\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3806 - val_loss: 0.3651\n",
      "Epoch 62/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3809 - val_loss: 0.3658\n",
      "Epoch 63/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3805 - val_loss: 0.3692\n",
      "Epoch 64/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3844 - val_loss: 0.3641\n",
      "Epoch 65/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3793 - val_loss: 0.3668\n",
      "Epoch 66/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3868 - val_loss: 0.3656\n",
      "Epoch 67/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3788 - val_loss: 0.3662\n",
      "Epoch 68/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3816 - val_loss: 0.3662\n",
      "Epoch 69/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3789 - val_loss: 0.3647\n",
      "Epoch 70/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3835 - val_loss: 0.3609\n",
      "Epoch 71/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3767 - val_loss: 0.3656\n",
      "Epoch 72/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3845 - val_loss: 0.3641\n",
      "Epoch 73/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3783 - val_loss: 0.3645\n",
      "Epoch 74/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3871 - val_loss: 0.3618\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3757 - val_loss: 0.3568\n",
      "Epoch 76/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3741 - val_loss: 0.3586\n",
      "Epoch 77/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3730 - val_loss: 0.3582\n",
      "Epoch 78/100\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3743 - val_loss: 0.3574\n",
      "Epoch 79/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3718 - val_loss: 0.3568\n",
      "Epoch 80/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3740 - val_loss: 0.3546\n",
      "Epoch 81/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3714 - val_loss: 0.3569\n",
      "Epoch 82/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3709 - val_loss: 0.3542\n",
      "Epoch 83/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3700 - val_loss: 0.3541\n",
      "Epoch 84/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3707 - val_loss: 0.3538\n",
      "Epoch 85/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3693 - val_loss: 0.3562\n",
      "Epoch 86/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3708 - val_loss: 0.3551\n",
      "Epoch 87/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3694 - val_loss: 0.3526\n",
      "Epoch 88/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3688 - val_loss: 0.3536\n",
      "Epoch 89/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3685 - val_loss: 0.3556\n",
      "Epoch 90/100\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3675 - val_loss: 0.3539\n",
      "Epoch 91/100\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3674 - val_loss: 0.3564\n",
      "Epoch 92/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3684 - val_loss: 0.3561\n",
      "Epoch 93/100\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.3676 - val_loss: 0.3527\n",
      "Epoch 94/100\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3664 - val_loss: 0.3511\n",
      "Epoch 95/100\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3668 - val_loss: 0.3515\n",
      "Epoch 96/100\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3753 - val_loss: 0.3527\n",
      "Epoch 97/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3662 - val_loss: 0.3566\n",
      "Epoch 98/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3733 - val_loss: 0.3551\n",
      "Epoch 99/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3650 - val_loss: 0.3541\n",
      "Epoch 100/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3638 - val_loss: 0.3522\n",
      "5160/5160 [==============================] - 0s 21us/sample - loss: 0.3595\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "validation_data=(X_valid, y_valid),\n",
    "callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 119us/sample - loss: 0.9094 - val_loss: 0.6116\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5545 - val_loss: 0.4858\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5100 - val_loss: 0.4544\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4851 - val_loss: 0.4423\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4798 - val_loss: 0.4959\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4690 - val_loss: 0.4353\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4515 - val_loss: 0.4299\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4465 - val_loss: 0.4251\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4381 - val_loss: 0.4216\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4322 - val_loss: 0.4121\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4321 - val_loss: 0.4103\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4403 - val_loss: 0.4126\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4193 - val_loss: 0.4070\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4150 - val_loss: 0.4014\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4095 - val_loss: 0.4009\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4058 - val_loss: 0.3966\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4045 - val_loss: 0.3924\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3996 - val_loss: 0.4016\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3971 - val_loss: 0.3988\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3919 - val_loss: 0.3884\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3889 - val_loss: 0.3834\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3872 - val_loss: 0.3838\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3837 - val_loss: 0.3809\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3805 - val_loss: 0.3784\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3777 - val_loss: 0.3826\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3785 - val_loss: 0.3769\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3793 - val_loss: 0.3735\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3720 - val_loss: 0.3763\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3700 - val_loss: 0.3694\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3657 - val_loss: 0.3708\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3650 - val_loss: 0.3688\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3640 - val_loss: 0.3616\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3673 - val_loss: 0.3606\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3608 - val_loss: 0.3627\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3584 - val_loss: 0.3563\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3556 - val_loss: 0.3525\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3566 - val_loss: 0.3521\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3589 - val_loss: 0.3508\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3524 - val_loss: 0.3500\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3552 - val_loss: 0.3477\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3515 - val_loss: 0.3421\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3537 - val_loss: 0.3449\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3482 - val_loss: 0.3413\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3467 - val_loss: 0.3384\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3438 - val_loss: 0.3374\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3424 - val_loss: 0.3356\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3429 - val_loss: 0.3344\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3415 - val_loss: 0.3380\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3394 - val_loss: 0.3468\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3377 - val_loss: 0.3362\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3357 - val_loss: 0.3452\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3358 - val_loss: 0.3341\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3340 - val_loss: 0.3314\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3332 - val_loss: 0.3333\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3323 - val_loss: 0.3328\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3300 - val_loss: 0.3319\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3299 - val_loss: 0.3380\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3286 - val_loss: 0.3272\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3269 - val_loss: 0.3323\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3269 - val_loss: 0.3308\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3267 - val_loss: 0.3317\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3252 - val_loss: 0.3406\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3239 - val_loss: 0.3362\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3225 - val_loss: 0.3389\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3223 - val_loss: 0.3312\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3213 - val_loss: 0.3314\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3199 - val_loss: 0.3349\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3168 - val_loss: 0.3353\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.4174\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 1.4753 - val_loss: 0.7001\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6757 - val_loss: 0.6526\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6127 - val_loss: 0.5258\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5385 - val_loss: 0.4921\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5041 - val_loss: 0.4760\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4898 - val_loss: 0.4564\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4696 - val_loss: 0.4481\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4581 - val_loss: 0.4407\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4537 - val_loss: 0.4336\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4397 - val_loss: 0.4231\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4348 - val_loss: 0.4250\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4346 - val_loss: 0.4089\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4242 - val_loss: 0.4059\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4157 - val_loss: 0.3976\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4119 - val_loss: 0.3982\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4085 - val_loss: 0.3971\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4311 - val_loss: 0.4017\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4145 - val_loss: 0.4117\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4162 - val_loss: 0.3852\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4020 - val_loss: 0.3801\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3871 - val_loss: 0.3825\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3850 - val_loss: 0.3734\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3799 - val_loss: 0.3739\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3767 - val_loss: 0.3717\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3786 - val_loss: 0.3909\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3733 - val_loss: 0.3656\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3698 - val_loss: 0.3823\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3680 - val_loss: 0.3649\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3639 - val_loss: 0.3847\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3625 - val_loss: 0.3613\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3617 - val_loss: 0.3581\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3581 - val_loss: 0.3610\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3569 - val_loss: 0.3572\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3532 - val_loss: 0.3704\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3545 - val_loss: 0.3546\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3503 - val_loss: 0.3554\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3495 - val_loss: 0.3530\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3525 - val_loss: 0.3650\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3538 - val_loss: 0.3542\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3613 - val_loss: 0.3745\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3696 - val_loss: 0.3495\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3494 - val_loss: 0.3513\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3454 - val_loss: 0.3476\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3428 - val_loss: 0.3493\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3433 - val_loss: 0.3491\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3397 - val_loss: 0.3429\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3397 - val_loss: 0.3456\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3389 - val_loss: 0.3425\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3397 - val_loss: 0.3478\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3340 - val_loss: 0.3408\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3343 - val_loss: 0.3384\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3347 - val_loss: 0.3483\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3396 - val_loss: 0.3382\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3307 - val_loss: 0.3353\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3311 - val_loss: 0.3380\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3329 - val_loss: 0.3766\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3383 - val_loss: 0.3368\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3292 - val_loss: 0.3356\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3342 - val_loss: 0.3350\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3250 - val_loss: 0.3446\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3251 - val_loss: 0.3375\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3266 - val_loss: 0.3326\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3251 - val_loss: 0.3352\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3219 - val_loss: 0.3298\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3217 - val_loss: 0.3396\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3207 - val_loss: 0.3503\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3223 - val_loss: 0.3316\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3218 - val_loss: 0.3264\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3231 - val_loss: 0.3283\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3199 - val_loss: 0.3273\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3171 - val_loss: 0.3367\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3165 - val_loss: 0.3332\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3178 - val_loss: 0.3272\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3221 - val_loss: 0.3291\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3150 - val_loss: 0.3625\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3199 - val_loss: 0.3218\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3125 - val_loss: 0.3267\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3120 - val_loss: 0.3343\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3123 - val_loss: 0.3272\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3130 - val_loss: 0.3191\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3118 - val_loss: 0.3250\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3118 - val_loss: 0.3229\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3146 - val_loss: 0.3266\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3107 - val_loss: 0.3206\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3086 - val_loss: 0.3214\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3199 - val_loss: 0.3257\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3068 - val_loss: 0.3170\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3072 - val_loss: 0.3164\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3071 - val_loss: 0.3213\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3125 - val_loss: 0.3201\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3051 - val_loss: 0.3234\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3105 - val_loss: 0.3140\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3035 - val_loss: 0.3122\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3074 - val_loss: 0.3113\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3029 - val_loss: 0.3160\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3029 - val_loss: 0.3205\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3049 - val_loss: 0.3225\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3043 - val_loss: 0.3175\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3106 - val_loss: 0.3163\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3073 - val_loss: 0.3225\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.3455\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 1.3412 - val_loss: 0.6569\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6368 - val_loss: 0.5424\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5460 - val_loss: 0.4910\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5051 - val_loss: 0.4642\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4812 - val_loss: 0.4511\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4656 - val_loss: 0.4367\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4551 - val_loss: 0.4324\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4462 - val_loss: 0.4199\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4396 - val_loss: 0.4153\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4350 - val_loss: 0.4125\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4289 - val_loss: 0.4148\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4255 - val_loss: 0.4103\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4221 - val_loss: 0.4017\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4181 - val_loss: 0.4019\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4141 - val_loss: 0.3960\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4118 - val_loss: 0.3982\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4087 - val_loss: 0.3922\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4044 - val_loss: 0.4015\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4022 - val_loss: 0.3847\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4005 - val_loss: 0.3838\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3978 - val_loss: 0.3834\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3946 - val_loss: 0.3844\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3918 - val_loss: 0.3884\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3899 - val_loss: 0.3792\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3884 - val_loss: 0.3803\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3856 - val_loss: 0.3740\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3832 - val_loss: 0.3738\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3819 - val_loss: 0.3695\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3792 - val_loss: 0.3681\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3776 - val_loss: 0.3697\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3763 - val_loss: 0.3669\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3736 - val_loss: 0.3642\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3724 - val_loss: 0.3663\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3694 - val_loss: 0.3639\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3677 - val_loss: 0.3652\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3675 - val_loss: 0.3631\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3647 - val_loss: 0.3601\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3632 - val_loss: 0.3611\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3622 - val_loss: 0.3605\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3594 - val_loss: 0.3619\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3590 - val_loss: 0.3590\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3599 - val_loss: 0.3551\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3551 - val_loss: 0.3535\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3542 - val_loss: 0.3552\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3525 - val_loss: 0.3529\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3509 - val_loss: 0.3595\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3498 - val_loss: 0.3470\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3488 - val_loss: 0.3473\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3478 - val_loss: 0.3447\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3455 - val_loss: 0.3433\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3451 - val_loss: 0.3433\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3431 - val_loss: 0.3501\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3418 - val_loss: 0.3439\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3418 - val_loss: 0.3465\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3408 - val_loss: 0.3472\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3409 - val_loss: 0.3505\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3369 - val_loss: 0.3368\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3365 - val_loss: 0.3396\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3373 - val_loss: 0.3381\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3364 - val_loss: 0.3371\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3319 - val_loss: 0.3379\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3304 - val_loss: 0.3349\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3296 - val_loss: 0.3327\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3291 - val_loss: 0.3343\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3278 - val_loss: 0.3314\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3274 - val_loss: 0.3333\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3257 - val_loss: 0.3307\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3260 - val_loss: 0.3299\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3236 - val_loss: 0.3357\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3240 - val_loss: 0.3281\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3225 - val_loss: 0.3307\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3216 - val_loss: 0.3292\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3218 - val_loss: 0.3259\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3212 - val_loss: 0.3279\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3207 - val_loss: 0.3282\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3196 - val_loss: 0.3290\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3178 - val_loss: 0.3259\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3192 - val_loss: 0.3238\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3181 - val_loss: 0.3233\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3154 - val_loss: 0.3365\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3165 - val_loss: 0.3238\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3165 - val_loss: 0.3288\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3176 - val_loss: 0.3283\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3168 - val_loss: 0.3378\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3154 - val_loss: 0.3225\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3137 - val_loss: 0.3239\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3153 - val_loss: 0.3263\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3129 - val_loss: 0.3528\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3148 - val_loss: 0.3230\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3130 - val_loss: 0.3241\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3130 - val_loss: 0.3212\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3130 - val_loss: 0.3233\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3111 - val_loss: 0.3267\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3116 - val_loss: 0.3298\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3115 - val_loss: 0.3205\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3111 - val_loss: 0.3285\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3124 - val_loss: 0.3226\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3105 - val_loss: 0.3349\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3104 - val_loss: 0.3255\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3089 - val_loss: 0.3232\n",
      "3870/3870 [==============================] - 0s 24us/sample - loss: 0.3330\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 3.9597 - val_loss: 2.2700\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 1.6834 - val_loss: 1.1508\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.9724 - val_loss: 0.7935\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7380 - val_loss: 0.6758\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6560 - val_loss: 0.6361\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6243 - val_loss: 0.6218\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6093 - val_loss: 0.6161\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6004 - val_loss: 0.6133\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5938 - val_loss: 0.6115\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5883 - val_loss: 0.6107\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5835 - val_loss: 0.6101\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5792 - val_loss: 0.6096\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5753 - val_loss: 0.6097\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5717 - val_loss: 0.6102\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5684 - val_loss: 0.6110\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5654 - val_loss: 0.6119\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5626 - val_loss: 0.6131\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5600 - val_loss: 0.6151\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5577 - val_loss: 0.6166\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5556 - val_loss: 0.6186\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5538 - val_loss: 0.6204\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5520 - val_loss: 0.6227\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 1.1168\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 3.8033 - val_loss: 2.0632\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 1.5497 - val_loss: 1.0286\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.8963 - val_loss: 0.6914\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6794 - val_loss: 0.5785\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6032 - val_loss: 0.5400\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5748 - val_loss: 0.5266\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5634 - val_loss: 0.5209\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5579 - val_loss: 0.5181\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5546 - val_loss: 0.5170\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5523 - val_loss: 0.5157\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5503 - val_loss: 0.5142\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5484 - val_loss: 0.5124\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5472 - val_loss: 0.5118\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5456 - val_loss: 0.5102\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5446 - val_loss: 0.5097\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5437 - val_loss: 0.5095\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5424 - val_loss: 0.5081\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5413 - val_loss: 0.5071\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5406 - val_loss: 0.5062\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5401 - val_loss: 0.5061\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5390 - val_loss: 0.5050\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5384 - val_loss: 0.5041\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5383 - val_loss: 0.5050\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5373 - val_loss: 0.5039\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5370 - val_loss: 0.5037\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5365 - val_loss: 0.5040\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5359 - val_loss: 0.5029\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5354 - val_loss: 0.5021\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5358 - val_loss: 0.5027\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5352 - val_loss: 0.5025\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5349 - val_loss: 0.5030\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5346 - val_loss: 0.5034\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5344 - val_loss: 0.5026\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5337 - val_loss: 0.5012\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5342 - val_loss: 0.5013\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5337 - val_loss: 0.5031\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5337 - val_loss: 0.5023\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5335 - val_loss: 0.5026\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5333 - val_loss: 0.5025\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5332 - val_loss: 0.5031\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5327 - val_loss: 0.5010\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5321 - val_loss: 0.5006\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5331 - val_loss: 0.5016\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5329 - val_loss: 0.5021\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5328 - val_loss: 0.5024\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5325 - val_loss: 0.5031\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5327 - val_loss: 0.5026\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5325 - val_loss: 0.5017\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5326 - val_loss: 0.5024\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5325 - val_loss: 0.5018\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5321 - val_loss: 0.5007\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5324 - val_loss: 0.5016\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.5523\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 85us/sample - loss: 5.5539 - val_loss: 2.8381\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 2.1471 - val_loss: 1.3964\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 1.2223 - val_loss: 0.9243\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.9138 - val_loss: 0.7579\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.7979 - val_loss: 0.6934\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7473 - val_loss: 0.6632\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7199 - val_loss: 0.6451\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7014 - val_loss: 0.6314\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6868 - val_loss: 0.6198\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6742 - val_loss: 0.6095\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6628 - val_loss: 0.6000\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6525 - val_loss: 0.5912\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6430 - val_loss: 0.5831\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6343 - val_loss: 0.5756\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6263 - val_loss: 0.5689\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6189 - val_loss: 0.5625\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6121 - val_loss: 0.5568\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6058 - val_loss: 0.5515\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6001 - val_loss: 0.5466\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5948 - val_loss: 0.5422\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5899 - val_loss: 0.5380\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5854 - val_loss: 0.5344\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5813 - val_loss: 0.5310\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5774 - val_loss: 0.5280\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5739 - val_loss: 0.5252\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5708 - val_loss: 0.5226\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5677 - val_loss: 0.5202\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5649 - val_loss: 0.5181\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5624 - val_loss: 0.5162\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5601 - val_loss: 0.5143\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5579 - val_loss: 0.5128\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5560 - val_loss: 0.5112\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5541 - val_loss: 0.5098\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5525 - val_loss: 0.5086\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5510 - val_loss: 0.5075\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5496 - val_loss: 0.5065\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5483 - val_loss: 0.5056\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5470 - val_loss: 0.5047\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5459 - val_loss: 0.5040\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5449 - val_loss: 0.5033\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5440 - val_loss: 0.5028\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5431 - val_loss: 0.5021\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5423 - val_loss: 0.5015\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5416 - val_loss: 0.5012\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5409 - val_loss: 0.5008\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5403 - val_loss: 0.5004\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5397 - val_loss: 0.5001\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5392 - val_loss: 0.4998\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5387 - val_loss: 0.4997\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5382 - val_loss: 0.4994\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5378 - val_loss: 0.4992\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5374 - val_loss: 0.4990\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5371 - val_loss: 0.4988\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5367 - val_loss: 0.4987\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5365 - val_loss: 0.4985\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5362 - val_loss: 0.4984\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5360 - val_loss: 0.4983\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5357 - val_loss: 0.4982\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5354 - val_loss: 0.4981\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5353 - val_loss: 0.4981\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5351 - val_loss: 0.4980\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5349 - val_loss: 0.4980\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5348 - val_loss: 0.4980\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5347 - val_loss: 0.4980\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5345 - val_loss: 0.4978\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5344 - val_loss: 0.4978\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5343 - val_loss: 0.4979\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5342 - val_loss: 0.4979\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5341 - val_loss: 0.4979\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5340 - val_loss: 0.4978\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5340 - val_loss: 0.4978\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5339 - val_loss: 0.4979\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5338 - val_loss: 0.4979\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5337 - val_loss: 0.4980\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5337 - val_loss: 0.4981\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5338 - val_loss: 0.4980\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5336 - val_loss: 0.4981\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5335 - val_loss: 0.4981\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5336 - val_loss: 0.4981\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5335 - val_loss: 0.4980\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5334 - val_loss: 0.4981\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.5548\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 4.0918 - val_loss: 2.4684\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 1.9151 - val_loss: 1.3151\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 1.2115 - val_loss: 0.9945\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.9812 - val_loss: 0.8831\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.8885 - val_loss: 0.8282\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.8398 - val_loss: 0.7922\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.8082 - val_loss: 0.7652\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7850 - val_loss: 0.7436\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7666 - val_loss: 0.7250\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7508 - val_loss: 0.7085\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7368 - val_loss: 0.6942\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.7241 - val_loss: 0.6806\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.7124 - val_loss: 0.6683\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7014 - val_loss: 0.6574\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6914 - val_loss: 0.6465\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6816 - val_loss: 0.6361\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6727 - val_loss: 0.6274\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6643 - val_loss: 0.6185\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6561 - val_loss: 0.6103\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6484 - val_loss: 0.6025\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6411 - val_loss: 0.5949\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6341 - val_loss: 0.5880\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6275 - val_loss: 0.5816\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6210 - val_loss: 0.5752\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6149 - val_loss: 0.5694\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6090 - val_loss: 0.5637\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6033 - val_loss: 0.5579\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5978 - val_loss: 0.5531\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5927 - val_loss: 0.5480\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5877 - val_loss: 0.5433\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5829 - val_loss: 0.5392\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5782 - val_loss: 0.5352\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5737 - val_loss: 0.5311\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5693 - val_loss: 0.5275\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5651 - val_loss: 0.5239\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5610 - val_loss: 0.5203\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5570 - val_loss: 0.5171\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5532 - val_loss: 0.5141\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5495 - val_loss: 0.5114\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5459 - val_loss: 0.5085\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5424 - val_loss: 0.5059\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5390 - val_loss: 0.5034\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5358 - val_loss: 0.5013\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5326 - val_loss: 0.4991\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5295 - val_loss: 0.4972\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5266 - val_loss: 0.4949\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5237 - val_loss: 0.4931\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5209 - val_loss: 0.4912\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5182 - val_loss: 0.4894\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5155 - val_loss: 0.4878\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5130 - val_loss: 0.4864\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5104 - val_loss: 0.4855\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5080 - val_loss: 0.4840\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5057 - val_loss: 0.4825\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5035 - val_loss: 0.4815\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5013 - val_loss: 0.4802\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4991 - val_loss: 0.4794\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4971 - val_loss: 0.4784\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4950 - val_loss: 0.4776\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4932 - val_loss: 0.4764\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4913 - val_loss: 0.4757\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4894 - val_loss: 0.4749\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4877 - val_loss: 0.4743\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4859 - val_loss: 0.4734\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4842 - val_loss: 0.4728\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4828 - val_loss: 0.4725\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4813 - val_loss: 0.4724\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4798 - val_loss: 0.4721\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4783 - val_loss: 0.4716\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4769 - val_loss: 0.4715\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4756 - val_loss: 0.4710\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4741 - val_loss: 0.4710\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4730 - val_loss: 0.4710\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4717 - val_loss: 0.4709\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4705 - val_loss: 0.4710\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4693 - val_loss: 0.4711\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4682 - val_loss: 0.4709\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4668 - val_loss: 0.4713\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4659 - val_loss: 0.4711\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4648 - val_loss: 0.4709\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4636 - val_loss: 0.4708\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4627 - val_loss: 0.4714\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4616 - val_loss: 0.4714\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4607 - val_loss: 0.4720\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4596 - val_loss: 0.4717\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4587 - val_loss: 0.4720\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4578 - val_loss: 0.4723\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4570 - val_loss: 0.4728\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4560 - val_loss: 0.4729\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4552 - val_loss: 0.4739\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4544 - val_loss: 0.4744\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.6804\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 3.7504 - val_loss: 2.4124\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 1.8750 - val_loss: 1.3517\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 1.1963 - val_loss: 0.9692\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.9462 - val_loss: 0.8357\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.8402 - val_loss: 0.7733\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.7878 - val_loss: 0.7370\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7565 - val_loss: 0.7120\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7347 - val_loss: 0.6928\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7173 - val_loss: 0.6769\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7024 - val_loss: 0.6631\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6891 - val_loss: 0.6500\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6769 - val_loss: 0.6384\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6657 - val_loss: 0.6283\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6554 - val_loss: 0.6180\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6456 - val_loss: 0.6081\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6366 - val_loss: 0.5999\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6278 - val_loss: 0.5921\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6197 - val_loss: 0.5836\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6121 - val_loss: 0.5761\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6047 - val_loss: 0.5695\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5978 - val_loss: 0.5632\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5911 - val_loss: 0.5566\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5850 - val_loss: 0.5509\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5789 - val_loss: 0.5455\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5733 - val_loss: 0.5404\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5678 - val_loss: 0.5352\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5625 - val_loss: 0.5304\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5576 - val_loss: 0.5262\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5529 - val_loss: 0.5217\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5482 - val_loss: 0.5181\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5441 - val_loss: 0.5138\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5398 - val_loss: 0.5105\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5358 - val_loss: 0.5067\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5320 - val_loss: 0.5037\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5284 - val_loss: 0.5000\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5251 - val_loss: 0.4970\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5217 - val_loss: 0.4942\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5184 - val_loss: 0.4915\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5154 - val_loss: 0.4888\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5124 - val_loss: 0.4868\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5097 - val_loss: 0.4837\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5069 - val_loss: 0.4812\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5044 - val_loss: 0.4790\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5018 - val_loss: 0.4770\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4994 - val_loss: 0.4748\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4970 - val_loss: 0.4727\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4947 - val_loss: 0.4706\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4925 - val_loss: 0.4686\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4904 - val_loss: 0.4669\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4884 - val_loss: 0.4652\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4864 - val_loss: 0.4635\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4845 - val_loss: 0.4622\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4825 - val_loss: 0.4604\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4805 - val_loss: 0.4597\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4791 - val_loss: 0.4572\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4773 - val_loss: 0.4562\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4757 - val_loss: 0.4546\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4740 - val_loss: 0.4533\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4725 - val_loss: 0.4514\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4709 - val_loss: 0.4503\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4695 - val_loss: 0.4490\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4679 - val_loss: 0.4480\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4665 - val_loss: 0.4472\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4653 - val_loss: 0.4454\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4639 - val_loss: 0.4445\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4626 - val_loss: 0.4434\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4613 - val_loss: 0.4422\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4600 - val_loss: 0.4412\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4587 - val_loss: 0.4401\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4577 - val_loss: 0.4391\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4565 - val_loss: 0.4379\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4552 - val_loss: 0.4378\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4542 - val_loss: 0.4367\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4531 - val_loss: 0.4357\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4520 - val_loss: 0.4346\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4509 - val_loss: 0.4335\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4499 - val_loss: 0.4329\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4489 - val_loss: 0.4315\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4478 - val_loss: 0.4307\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4469 - val_loss: 0.4302\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4459 - val_loss: 0.4292\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4450 - val_loss: 0.4287\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4440 - val_loss: 0.4282\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4432 - val_loss: 0.4271\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4422 - val_loss: 0.4255\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4414 - val_loss: 0.4251\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4404 - val_loss: 0.4251\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4397 - val_loss: 0.4241\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4389 - val_loss: 0.4229\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4381 - val_loss: 0.4223\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4372 - val_loss: 0.4220\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4364 - val_loss: 0.4207\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4356 - val_loss: 0.4204\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4348 - val_loss: 0.4197\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4340 - val_loss: 0.4188\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4332 - val_loss: 0.4189\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4324 - val_loss: 0.4186\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4318 - val_loss: 0.4181\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4310 - val_loss: 0.4165\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4303 - val_loss: 0.4154\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.4551\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 3.1885 - val_loss: 2.0664\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.7864 - val_loss: 1.2958\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 1.2368 - val_loss: 0.9965\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.9706 - val_loss: 0.8481\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.8386 - val_loss: 0.7636\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - ETA: 0s - loss: 0.752 - 0s 43us/sample - loss: 0.7667 - val_loss: 0.7136\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7249 - val_loss: 0.6813\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6985 - val_loss: 0.6599\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6801 - val_loss: 0.6435\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6659 - val_loss: 0.6300\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6543 - val_loss: 0.6189\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6442 - val_loss: 0.6091\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6351 - val_loss: 0.6001\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6266 - val_loss: 0.5914\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6188 - val_loss: 0.5842\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6114 - val_loss: 0.5771\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6045 - val_loss: 0.5702\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5979 - val_loss: 0.5636\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5917 - val_loss: 0.5572\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5857 - val_loss: 0.5510\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5801 - val_loss: 0.5454\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5746 - val_loss: 0.5401\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5694 - val_loss: 0.5350\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5645 - val_loss: 0.5305\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5598 - val_loss: 0.5261\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5553 - val_loss: 0.5214\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5510 - val_loss: 0.5169\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5468 - val_loss: 0.5132\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5427 - val_loss: 0.5099\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5390 - val_loss: 0.5058\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5353 - val_loss: 0.5022\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5318 - val_loss: 0.4986\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5284 - val_loss: 0.4952\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5251 - val_loss: 0.4932\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5221 - val_loss: 0.4895\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5191 - val_loss: 0.4866\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5161 - val_loss: 0.4845\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5134 - val_loss: 0.4811\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5108 - val_loss: 0.4791\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5082 - val_loss: 0.4765\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5057 - val_loss: 0.4742\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5034 - val_loss: 0.4718\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5011 - val_loss: 0.4701\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4989 - val_loss: 0.4677\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4969 - val_loss: 0.4658\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4947 - val_loss: 0.4643\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4928 - val_loss: 0.4621\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4909 - val_loss: 0.4606\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4891 - val_loss: 0.4590\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4873 - val_loss: 0.4570\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4857 - val_loss: 0.4554\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4840 - val_loss: 0.4546\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4824 - val_loss: 0.4531\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4809 - val_loss: 0.4515\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4794 - val_loss: 0.4500\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4779 - val_loss: 0.4490\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4765 - val_loss: 0.4486\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4752 - val_loss: 0.4465\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4738 - val_loss: 0.4452\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4727 - val_loss: 0.4442\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4712 - val_loss: 0.4437\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4701 - val_loss: 0.4426\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4690 - val_loss: 0.4415\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4678 - val_loss: 0.4408\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4667 - val_loss: 0.4394\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4656 - val_loss: 0.4382\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4645 - val_loss: 0.4380\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4635 - val_loss: 0.4365\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4625 - val_loss: 0.4365\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4615 - val_loss: 0.4356\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4606 - val_loss: 0.4347\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4597 - val_loss: 0.4342\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4587 - val_loss: 0.4330\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4578 - val_loss: 0.4327\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4570 - val_loss: 0.4320\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4561 - val_loss: 0.4312\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4553 - val_loss: 0.4302\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4544 - val_loss: 0.4302\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4536 - val_loss: 0.4294\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4528 - val_loss: 0.4293\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4522 - val_loss: 0.4279\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4513 - val_loss: 0.4275\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4505 - val_loss: 0.4260\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4498 - val_loss: 0.4258\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4491 - val_loss: 0.4256\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4483 - val_loss: 0.4245\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4477 - val_loss: 0.4246\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4470 - val_loss: 0.4236\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4463 - val_loss: 0.4233\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4456 - val_loss: 0.4228\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4449 - val_loss: 0.4219\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4443 - val_loss: 0.4215\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4437 - val_loss: 0.4210\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4431 - val_loss: 0.4205\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4425 - val_loss: 0.4204\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4418 - val_loss: 0.4194\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4412 - val_loss: 0.4197\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4407 - val_loss: 0.4191\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4401 - val_loss: 0.4187\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4395 - val_loss: 0.4177\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.4516\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 1.3689 - val_loss: 0.6757\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6616 - val_loss: 0.5910\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6028 - val_loss: 0.5355\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5631 - val_loss: 0.5028\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5370 - val_loss: 0.4853\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5132 - val_loss: 0.4706\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4988 - val_loss: 0.4658\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4870 - val_loss: 0.4605\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4774 - val_loss: 0.4604\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4706 - val_loss: 0.4603\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4634 - val_loss: 0.4621\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4579 - val_loss: 0.4663\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4534 - val_loss: 0.4667\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4484 - val_loss: 0.4735\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4444 - val_loss: 0.4792\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4416 - val_loss: 0.4809\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4409 - val_loss: 0.4844\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4350 - val_loss: 0.4937\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4332 - val_loss: 0.4955\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4298 - val_loss: 0.5005\n",
      "3870/3870 [==============================] - 0s 25us/sample - loss: 0.9000\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 103us/sample - loss: 1.7035 - val_loss: 0.7965\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.8864 - val_loss: 0.6927\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.7039 - val_loss: 0.6107\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6223 - val_loss: 0.5625\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5805 - val_loss: 0.5287\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5481 - val_loss: 0.5051\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5240 - val_loss: 0.4883\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5064 - val_loss: 0.4757\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4913 - val_loss: 0.4599\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4792 - val_loss: 0.4494\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4745 - val_loss: 0.4473\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4641 - val_loss: 0.4407\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4579 - val_loss: 0.4366\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4521 - val_loss: 0.4332\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4476 - val_loss: 0.4279\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4433 - val_loss: 0.4282\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4414 - val_loss: 0.4192\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4373 - val_loss: 0.4166\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4342 - val_loss: 0.4144\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4309 - val_loss: 0.4114\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4282 - val_loss: 0.4114\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4256 - val_loss: 0.4138\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4232 - val_loss: 0.4073\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4203 - val_loss: 0.4061\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4176 - val_loss: 0.4000\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4155 - val_loss: 0.3988\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4136 - val_loss: 0.3977\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4115 - val_loss: 0.3973\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4096 - val_loss: 0.3941\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4080 - val_loss: 0.3932\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4056 - val_loss: 0.3948\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4037 - val_loss: 0.3885\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4018 - val_loss: 0.3902\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4007 - val_loss: 0.3864\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3989 - val_loss: 0.3851\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3972 - val_loss: 0.3831\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3949 - val_loss: 0.3873\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3956 - val_loss: 0.3845\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3927 - val_loss: 0.3794\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3917 - val_loss: 0.3785\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3895 - val_loss: 0.3796\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 85us/sample - loss: 0.3880 - val_loss: 0.3776\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 0.3873 - val_loss: 0.3760\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 0.3872 - val_loss: 0.3729\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3843 - val_loss: 0.3735\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3846 - val_loss: 0.3741\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3831 - val_loss: 0.3715\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3803 - val_loss: 0.3706\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3793 - val_loss: 0.3692\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3784 - val_loss: 0.3682\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3776 - val_loss: 0.3680\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3774 - val_loss: 0.3697\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3753 - val_loss: 0.3663\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3750 - val_loss: 0.3680\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3799 - val_loss: 0.3657\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3726 - val_loss: 0.3635\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3728 - val_loss: 0.3684\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3721 - val_loss: 0.3636\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3712 - val_loss: 0.3638\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3697 - val_loss: 0.3632\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3735 - val_loss: 0.3653\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3730 - val_loss: 0.3635\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3708 - val_loss: 0.3609\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3693 - val_loss: 0.3583\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3653 - val_loss: 0.3591\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3637 - val_loss: 0.3595\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3640 - val_loss: 0.3613\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3634 - val_loss: 0.3617\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3625 - val_loss: 0.3581\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3629 - val_loss: 0.3553\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3604 - val_loss: 0.3565\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3600 - val_loss: 0.3579\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3593 - val_loss: 0.3536\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3593 - val_loss: 0.3559\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3585 - val_loss: 0.3572\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3574 - val_loss: 0.3544\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3562 - val_loss: 0.3548\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3556 - val_loss: 0.3518\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3544 - val_loss: 0.3541\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3544 - val_loss: 0.3539\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3544 - val_loss: 0.3520\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3550 - val_loss: 0.3536\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3523 - val_loss: 0.3531\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3526 - val_loss: 0.3518\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3551 - val_loss: 0.3505\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3524 - val_loss: 0.3519\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3572 - val_loss: 0.3504\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3511 - val_loss: 0.3522\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3520 - val_loss: 0.3521\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3569 - val_loss: 0.3579\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3604 - val_loss: 0.3479\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3496 - val_loss: 0.3483\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3483 - val_loss: 0.3491\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3471 - val_loss: 0.3474\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3477 - val_loss: 0.3472\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3472 - val_loss: 0.3464\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3464 - val_loss: 0.3459\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3472 - val_loss: 0.3460\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3457 - val_loss: 0.3462\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3471 - val_loss: 0.3457\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.3801\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 1.2312 - val_loss: 0.9858\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 1.5857 - val_loss: 0.7369\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.7960 - val_loss: 0.5745\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5809 - val_loss: 0.5276\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5411 - val_loss: 0.4997\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5175 - val_loss: 0.4821\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5019 - val_loss: 0.4704\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4904 - val_loss: 0.4604\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4808 - val_loss: 0.4506\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4734 - val_loss: 0.4493\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4670 - val_loss: 0.4377\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4616 - val_loss: 0.4340\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4567 - val_loss: 0.4287\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4518 - val_loss: 0.4260\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4486 - val_loss: 0.4224\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4454 - val_loss: 0.4190\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4415 - val_loss: 0.4164\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4391 - val_loss: 0.4162\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4367 - val_loss: 0.4113\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4328 - val_loss: 0.4088\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4317 - val_loss: 0.4060\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4294 - val_loss: 0.4076\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4273 - val_loss: 0.4022\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4250 - val_loss: 0.4004\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4233 - val_loss: 0.3981\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4209 - val_loss: 0.3974\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4185 - val_loss: 0.4021\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4186 - val_loss: 0.3948\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4161 - val_loss: 0.3931\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4145 - val_loss: 0.3920\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4128 - val_loss: 0.3903\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4115 - val_loss: 0.3923\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4097 - val_loss: 0.3891\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4082 - val_loss: 0.3865\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4068 - val_loss: 0.3866\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4054 - val_loss: 0.3857\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4040 - val_loss: 0.3842\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4028 - val_loss: 0.3839\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4008 - val_loss: 0.3796\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3997 - val_loss: 0.3802\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3990 - val_loss: 0.3792\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3976 - val_loss: 0.3786\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3963 - val_loss: 0.3765\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3953 - val_loss: 0.3760\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3940 - val_loss: 0.3744\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3927 - val_loss: 0.3775\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3914 - val_loss: 0.3761\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3908 - val_loss: 0.3729\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3901 - val_loss: 0.3747\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3888 - val_loss: 0.3718\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3876 - val_loss: 0.3727\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3869 - val_loss: 0.3691\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3861 - val_loss: 0.3692\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3849 - val_loss: 0.3685\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3839 - val_loss: 0.3682\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3831 - val_loss: 0.3677\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3823 - val_loss: 0.3671\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3815 - val_loss: 0.3658\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3806 - val_loss: 0.3648\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3794 - val_loss: 0.3647\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3791 - val_loss: 0.3644\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3785 - val_loss: 0.3632\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3774 - val_loss: 0.3642\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3768 - val_loss: 0.3619\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3759 - val_loss: 0.3604\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3749 - val_loss: 0.3636\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3748 - val_loss: 0.3591\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3729 - val_loss: 0.3593\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3725 - val_loss: 0.3593\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3720 - val_loss: 0.3621\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3711 - val_loss: 0.3573\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3709 - val_loss: 0.3583\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3699 - val_loss: 0.3573\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3696 - val_loss: 0.3555\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3691 - val_loss: 0.3555\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3676 - val_loss: 0.3567\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3676 - val_loss: 0.3568\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3669 - val_loss: 0.3560\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3661 - val_loss: 0.3555\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3655 - val_loss: 0.3553\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3649 - val_loss: 0.3541\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3648 - val_loss: 0.3537\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3638 - val_loss: 0.3526\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3632 - val_loss: 0.3524\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3626 - val_loss: 0.3513\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3623 - val_loss: 0.3530\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3618 - val_loss: 0.3497\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3610 - val_loss: 0.3494\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3606 - val_loss: 0.3517\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3599 - val_loss: 0.3502\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3591 - val_loss: 0.3504\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3587 - val_loss: 0.3501\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3576 - val_loss: 0.3511\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3573 - val_loss: 0.3525\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3574 - val_loss: 0.3485\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3564 - val_loss: 0.3495\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3563 - val_loss: 0.3469\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3550 - val_loss: 0.3474\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3555 - val_loss: 0.3480\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3541 - val_loss: 0.3499\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3651\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 4.2940 - val_loss: 2.0197\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 1.4675 - val_loss: 0.9690\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.8232 - val_loss: 0.6816\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6454 - val_loss: 0.6004\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5950 - val_loss: 0.5762\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5793 - val_loss: 0.5661\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5730 - val_loss: 0.5599\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5696 - val_loss: 0.5550\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5671 - val_loss: 0.5502\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5652 - val_loss: 0.5462\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5634 - val_loss: 0.5420\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5619 - val_loss: 0.5381\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5604 - val_loss: 0.5348\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5590 - val_loss: 0.5316\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5579 - val_loss: 0.5278\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5564 - val_loss: 0.5242\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5556 - val_loss: 0.5214\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5549 - val_loss: 0.5192\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5538 - val_loss: 0.5181\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5532 - val_loss: 0.5158\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5518 - val_loss: 0.5127\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5518 - val_loss: 0.5117\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5509 - val_loss: 0.5099\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5504 - val_loss: 0.5090\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5497 - val_loss: 0.5074\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5492 - val_loss: 0.5071\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5480 - val_loss: 0.5045\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5482 - val_loss: 0.5053\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5473 - val_loss: 0.5034\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5473 - val_loss: 0.5031\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5466 - val_loss: 0.5024\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5463 - val_loss: 0.5023\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5461 - val_loss: 0.5021\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5452 - val_loss: 0.5014\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5456 - val_loss: 0.5020\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5448 - val_loss: 0.5020\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5442 - val_loss: 0.5021\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5446 - val_loss: 0.5030\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5434 - val_loss: 0.5060\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5438 - val_loss: 0.5050\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5430 - val_loss: 0.5048\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5430 - val_loss: 0.5054\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5430 - val_loss: 0.5065\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5427 - val_loss: 0.5093\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.5618\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 5.2260 - val_loss: 2.2589\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 1.6239 - val_loss: 1.0450\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.9157 - val_loss: 0.7159\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7155 - val_loss: 0.6175\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6505 - val_loss: 0.5850\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6248 - val_loss: 0.5708\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6114 - val_loss: 0.5622\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6021 - val_loss: 0.5555\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5946 - val_loss: 0.5497\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5879 - val_loss: 0.5446\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5824 - val_loss: 0.5403\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5772 - val_loss: 0.5359\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5727 - val_loss: 0.5322\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5686 - val_loss: 0.5290\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5649 - val_loss: 0.5262\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5616 - val_loss: 0.5233\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5587 - val_loss: 0.5211\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5558 - val_loss: 0.5185\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5535 - val_loss: 0.5170\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5513 - val_loss: 0.5157\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5495 - val_loss: 0.5138\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5473 - val_loss: 0.5116\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5461 - val_loss: 0.5113\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5448 - val_loss: 0.5103\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5435 - val_loss: 0.5097\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5420 - val_loss: 0.5075\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5415 - val_loss: 0.5081\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5406 - val_loss: 0.5076\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5397 - val_loss: 0.5066\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5388 - val_loss: 0.5051\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5384 - val_loss: 0.5061\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5376 - val_loss: 0.5047\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5367 - val_loss: 0.5033\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5368 - val_loss: 0.5033\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5360 - val_loss: 0.5026\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5357 - val_loss: 0.5022\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5354 - val_loss: 0.5015\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5355 - val_loss: 0.5022\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5352 - val_loss: 0.5024\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5347 - val_loss: 0.5023\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5340 - val_loss: 0.5015\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5343 - val_loss: 0.5015\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5338 - val_loss: 0.5013\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5340 - val_loss: 0.5011\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5334 - val_loss: 0.5007\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5340 - val_loss: 0.5012\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5334 - val_loss: 0.5010\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5332 - val_loss: 0.5005\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5332 - val_loss: 0.5011\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5326 - val_loss: 0.5000\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5335 - val_loss: 0.5006\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5323 - val_loss: 0.4998\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5334 - val_loss: 0.5010\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5338 - val_loss: 0.5022\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5328 - val_loss: 0.5029\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5326 - val_loss: 0.5031\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5329 - val_loss: 0.5030\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5317 - val_loss: 0.5005\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5329 - val_loss: 0.5011\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5323 - val_loss: 0.5005\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5326 - val_loss: 0.5031\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5319 - val_loss: 0.5006\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.5512\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 5.3286 - val_loss: 2.4874\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 1.7890 - val_loss: 1.1346\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.9815 - val_loss: 0.7377\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7388 - val_loss: 0.6178\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6600 - val_loss: 0.5792\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6302 - val_loss: 0.5640\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6158 - val_loss: 0.5556\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6065 - val_loss: 0.5495\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5993 - val_loss: 0.5442\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5931 - val_loss: 0.5394\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5875 - val_loss: 0.5352\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5826 - val_loss: 0.5313\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5780 - val_loss: 0.5276\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5739 - val_loss: 0.5243\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5702 - val_loss: 0.5212\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5668 - val_loss: 0.5187\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5638 - val_loss: 0.5164\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5609 - val_loss: 0.5142\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5584 - val_loss: 0.5123\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5560 - val_loss: 0.5107\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5540 - val_loss: 0.5092\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5521 - val_loss: 0.5077\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5503 - val_loss: 0.5066\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5487 - val_loss: 0.5053\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5473 - val_loss: 0.5044\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5460 - val_loss: 0.5035\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5448 - val_loss: 0.5026\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5438 - val_loss: 0.5019\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5428 - val_loss: 0.5014\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5419 - val_loss: 0.5008\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5411 - val_loss: 0.5005\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5404 - val_loss: 0.5000\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5397 - val_loss: 0.4997\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5391 - val_loss: 0.4993\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5385 - val_loss: 0.4990\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5380 - val_loss: 0.4988\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5375 - val_loss: 0.4985\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5372 - val_loss: 0.4983\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5368 - val_loss: 0.4982\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5365 - val_loss: 0.4981\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5361 - val_loss: 0.4979\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5359 - val_loss: 0.4978\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5356 - val_loss: 0.4978\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5354 - val_loss: 0.4977\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5352 - val_loss: 0.4976\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5350 - val_loss: 0.4977\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5347 - val_loss: 0.4976\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5347 - val_loss: 0.4976\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5345 - val_loss: 0.4977\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5344 - val_loss: 0.4976\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5343 - val_loss: 0.4976\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5342 - val_loss: 0.4976\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5341 - val_loss: 0.4977\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5339 - val_loss: 0.4978\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5339 - val_loss: 0.4978\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5339 - val_loss: 0.4978\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5337 - val_loss: 0.4977\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5337 - val_loss: 0.4977\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5337 - val_loss: 0.4977\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5336 - val_loss: 0.4978\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5336 - val_loss: 0.4978\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.5531\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 81us/sample - loss: 1.2594 - val_loss: 0.8446\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7422 - val_loss: 0.7095\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6503 - val_loss: 0.6136\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5848 - val_loss: 0.5459\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5458 - val_loss: 0.5031\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5129 - val_loss: 0.4753\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4955 - val_loss: 0.4632\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4810 - val_loss: 0.4464\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4698 - val_loss: 0.4410\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4619 - val_loss: 0.4286\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4545 - val_loss: 0.4263\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4483 - val_loss: 0.4181\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4410 - val_loss: 0.4183\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4371 - val_loss: 0.4124\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4334 - val_loss: 0.4177\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4304 - val_loss: 0.4080\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4243 - val_loss: 0.4071\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4208 - val_loss: 0.4014\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4173 - val_loss: 0.4023\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4137 - val_loss: 0.4015\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4103 - val_loss: 0.3997\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4071 - val_loss: 0.3997\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4043 - val_loss: 0.3986\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4006 - val_loss: 0.4069\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3979 - val_loss: 0.3976\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3960 - val_loss: 0.3960\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3932 - val_loss: 0.3976\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3912 - val_loss: 0.3955\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3888 - val_loss: 0.3971\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3860 - val_loss: 0.3983\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3842 - val_loss: 0.3939\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3809 - val_loss: 0.3962\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3791 - val_loss: 0.3955\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3773 - val_loss: 0.3926\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3758 - val_loss: 0.3931\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3736 - val_loss: 0.3950\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3715 - val_loss: 0.3901\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3705 - val_loss: 0.3893\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3686 - val_loss: 0.3909\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3677 - val_loss: 0.3963\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3641 - val_loss: 0.3931\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3629 - val_loss: 0.3852\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3618 - val_loss: 0.3842\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3605 - val_loss: 0.3860\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3587 - val_loss: 0.3876\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3574 - val_loss: 0.3818\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3555 - val_loss: 0.3925\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3552 - val_loss: 0.3832\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3528 - val_loss: 0.3816\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3520 - val_loss: 0.3793\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3506 - val_loss: 0.3769\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3487 - val_loss: 0.3714\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3476 - val_loss: 0.3770\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3454 - val_loss: 0.3738\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3446 - val_loss: 0.3684\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3425 - val_loss: 0.3790\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3416 - val_loss: 0.3698\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3403 - val_loss: 0.3662\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3393 - val_loss: 0.3673\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3389 - val_loss: 0.3756\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3380 - val_loss: 0.3607\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3360 - val_loss: 0.3633\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3354 - val_loss: 0.3600\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3357 - val_loss: 0.3644\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3333 - val_loss: 0.3683\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3341 - val_loss: 0.3597\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3309 - val_loss: 0.3530\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3285 - val_loss: 0.3518\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3290 - val_loss: 0.3481\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3267 - val_loss: 0.3483\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3264 - val_loss: 0.3450\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3249 - val_loss: 0.3501\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3245 - val_loss: 0.3431\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3234 - val_loss: 0.3507\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3225 - val_loss: 0.3389\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3216 - val_loss: 0.3389\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3208 - val_loss: 0.3419\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3204 - val_loss: 0.3363\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3195 - val_loss: 0.3370\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3186 - val_loss: 0.3317\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3176 - val_loss: 0.3503\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3166 - val_loss: 0.3373\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3161 - val_loss: 0.3272\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3164 - val_loss: 0.3423\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3157 - val_loss: 0.3280\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3137 - val_loss: 0.3305\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3131 - val_loss: 0.3397\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3130 - val_loss: 0.3246\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3126 - val_loss: 0.3315\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3109 - val_loss: 0.3221\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3093 - val_loss: 0.3228\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3110 - val_loss: 0.3253\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3106 - val_loss: 0.3163\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3093 - val_loss: 0.3270\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3093 - val_loss: 0.3226\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3089 - val_loss: 0.3153\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3073 - val_loss: 0.3189\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3083 - val_loss: 0.3170\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3065 - val_loss: 0.3168\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3056 - val_loss: 0.3115\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.3261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 1.4301 - val_loss: 0.6637\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6998 - val_loss: 0.5666\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5814 - val_loss: 0.5162\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5329 - val_loss: 0.4826\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4981 - val_loss: 0.4576\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4762 - val_loss: 0.4436\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4614 - val_loss: 0.4284\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4519 - val_loss: 0.4205\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4396 - val_loss: 0.4150\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4325 - val_loss: 0.4068\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4264 - val_loss: 0.4016\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4216 - val_loss: 0.3968\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4145 - val_loss: 0.3948\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4125 - val_loss: 0.3912\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4061 - val_loss: 0.3864\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4021 - val_loss: 0.3903\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3975 - val_loss: 0.3796\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3941 - val_loss: 0.3788\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3909 - val_loss: 0.3758\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3863 - val_loss: 0.3710\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3838 - val_loss: 0.3726\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3801 - val_loss: 0.3679\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3773 - val_loss: 0.3666\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3755 - val_loss: 0.3688\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3718 - val_loss: 0.3610\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3696 - val_loss: 0.3615\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3679 - val_loss: 0.3608\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3645 - val_loss: 0.3597\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3631 - val_loss: 0.3556\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3611 - val_loss: 0.3567\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3593 - val_loss: 0.3582\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3566 - val_loss: 0.3531\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3549 - val_loss: 0.3515\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3539 - val_loss: 0.3505\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3523 - val_loss: 0.3565\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3505 - val_loss: 0.3482\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3494 - val_loss: 0.3473\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3480 - val_loss: 0.3457\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3459 - val_loss: 0.3502\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3448 - val_loss: 0.3450\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3435 - val_loss: 0.3467\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3434 - val_loss: 0.3438\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3415 - val_loss: 0.3434\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3406 - val_loss: 0.3456\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3396 - val_loss: 0.3402\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3385 - val_loss: 0.3410\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3371 - val_loss: 0.3470\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3356 - val_loss: 0.3393\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3335 - val_loss: 0.3562\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3352 - val_loss: 0.3490\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3328 - val_loss: 0.3365\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3319 - val_loss: 0.3391\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3331 - val_loss: 0.3463\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3299 - val_loss: 0.3353\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3291 - val_loss: 0.3343\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3287 - val_loss: 0.3373\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3261 - val_loss: 0.3326\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3270 - val_loss: 0.3317\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3277 - val_loss: 0.3338\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3276 - val_loss: 0.3283\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3252 - val_loss: 0.3306\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3252 - val_loss: 0.3341\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3265 - val_loss: 0.3273\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3223 - val_loss: 0.3290\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3202 - val_loss: 0.3237\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3192 - val_loss: 0.3264\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3208 - val_loss: 0.3239\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3189 - val_loss: 0.3254\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3178 - val_loss: 0.3246\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3166 - val_loss: 0.3232\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3172 - val_loss: 0.3250\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3150 - val_loss: 0.3272\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3149 - val_loss: 0.3196\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3140 - val_loss: 0.3232\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3127 - val_loss: 0.3195\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3125 - val_loss: 0.3189\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3119 - val_loss: 0.3175\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3122 - val_loss: 0.3239\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3117 - val_loss: 0.3205\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3165 - val_loss: 0.3178\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3121 - val_loss: 0.3174\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3105 - val_loss: 0.3179\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3095 - val_loss: 0.3216\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3088 - val_loss: 0.3152\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3071 - val_loss: 0.3179\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3062 - val_loss: 0.3141\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3066 - val_loss: 0.3149\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3064 - val_loss: 0.3136\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3043 - val_loss: 0.3152\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3056 - val_loss: 0.3142\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3041 - val_loss: 0.3122\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3023 - val_loss: 0.3151\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3030 - val_loss: 0.3112\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3021 - val_loss: 0.3125\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3005 - val_loss: 0.3213\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3008 - val_loss: 0.3173\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3004 - val_loss: 0.3104\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.2990 - val_loss: 0.3118\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.2992 - val_loss: 0.3093\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2991 - val_loss: 0.3143\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.3326\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 1.2082 - val_loss: 0.6368\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6428 - val_loss: 0.5478\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5793 - val_loss: 0.5014\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5198 - val_loss: 0.4681\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4927 - val_loss: 0.4521\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4757 - val_loss: 0.4384\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4649 - val_loss: 0.4291\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4556 - val_loss: 0.4234\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4483 - val_loss: 0.4206\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4420 - val_loss: 0.4125\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4367 - val_loss: 0.4106\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4322 - val_loss: 0.4079\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4286 - val_loss: 0.4031\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4251 - val_loss: 0.3998\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4214 - val_loss: 0.3977\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4185 - val_loss: 0.3952\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4149 - val_loss: 0.3966\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4135 - val_loss: 0.3919\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4093 - val_loss: 0.3917\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4080 - val_loss: 0.3900\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4052 - val_loss: 0.3900\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4034 - val_loss: 0.3885\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4016 - val_loss: 0.3892\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4002 - val_loss: 0.3915\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3980 - val_loss: 0.3836\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3961 - val_loss: 0.3821\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3944 - val_loss: 0.3830\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3927 - val_loss: 0.3811\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3916 - val_loss: 0.3791\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3904 - val_loss: 0.3796\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3912 - val_loss: 0.3769\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3864 - val_loss: 0.3788\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3852 - val_loss: 0.3766\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3843 - val_loss: 0.3750\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3853 - val_loss: 0.3737\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3849 - val_loss: 0.3785\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3838 - val_loss: 0.3744\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3836 - val_loss: 0.3709\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3794 - val_loss: 0.3689\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3760 - val_loss: 0.3693\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3751 - val_loss: 0.3672\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3731 - val_loss: 0.3651\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3711 - val_loss: 0.3632\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - ETA: 0s - loss: 0.371 - 0s 45us/sample - loss: 0.3699 - val_loss: 0.3672\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3706 - val_loss: 0.3647\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3689 - val_loss: 0.3629\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3664 - val_loss: 0.3601\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3665 - val_loss: 0.3598\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3644 - val_loss: 0.3608\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3645 - val_loss: 0.3604\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3620 - val_loss: 0.3563\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3600 - val_loss: 0.3548\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3594 - val_loss: 0.3570\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3590 - val_loss: 0.3537\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3569 - val_loss: 0.3521\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3570 - val_loss: 0.3544\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3556 - val_loss: 0.3522\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3562 - val_loss: 0.3518\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3530 - val_loss: 0.3571\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3522 - val_loss: 0.3526\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3514 - val_loss: 0.3574\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3497 - val_loss: 0.3472\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3480 - val_loss: 0.3479\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 0.3487 - val_loss: 0.3551\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.3494 - val_loss: 0.3491\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3517 - val_loss: 0.3504\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3457 - val_loss: 0.3496\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3446 - val_loss: 0.3481\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3432 - val_loss: 0.3412\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3420 - val_loss: 0.3439\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3435 - val_loss: 0.3459\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3437 - val_loss: 0.3469\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3457 - val_loss: 0.3501\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3451 - val_loss: 0.3447\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3451 - val_loss: 0.3462\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3445 - val_loss: 0.3535\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3395 - val_loss: 0.3378\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3376 - val_loss: 0.3370\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3364 - val_loss: 0.3499\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3364 - val_loss: 0.3384\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3355 - val_loss: 0.3405\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3365 - val_loss: 0.3382\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3335 - val_loss: 0.3365\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3311 - val_loss: 0.3396\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3353 - val_loss: 0.3399\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3315 - val_loss: 0.3353\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3301 - val_loss: 0.3383\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3295 - val_loss: 0.3340\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3298 - val_loss: 0.3325\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3270 - val_loss: 0.3330\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3290 - val_loss: 0.3301\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3262 - val_loss: 0.3407\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3272 - val_loss: 0.3319\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3254 - val_loss: 0.3332\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3258 - val_loss: 0.3395\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3243 - val_loss: 0.3421\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3242 - val_loss: 0.3312\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3253 - val_loss: 0.3402\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3222 - val_loss: 0.3298\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3226 - val_loss: 0.3246\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.3270\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 1.0659 - val_loss: 0.7356\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6208 - val_loss: 0.6153\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6181 - val_loss: 0.5516\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5666 - val_loss: 0.5447\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6403 - val_loss: 0.5017\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5980 - val_loss: 0.5040\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5635 - val_loss: 0.5188\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5596 - val_loss: 0.5410\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5366 - val_loss: 0.5816\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5684 - val_loss: 1.6490\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6696 - val_loss: 0.9862\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5622 - val_loss: 0.7140\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5464 - val_loss: 1.5162\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6665 - val_loss: 0.8158\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5383 - val_loss: 0.8777\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 2.3895\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 1.2844 - val_loss: 0.6177\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 2.6268 - val_loss: 1.6854\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 1.4726 - val_loss: 16.0472\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 351.9470 - val_loss: 178.7695\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 3802.8779 - val_loss: 1988.3779\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 40919.7836 - val_loss: 23541.5518\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 458684.8365 - val_loss: 229389.2780\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 5064879.8602 - val_loss: 2314313.1592\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 51889665.9105 - val_loss: 26192583.1353\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 608601491.7593 - val_loss: 282067537.6331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 244917703.3596 - val_loss: 3211932121.5855\n",
      "3870/3870 [==============================] - 0s 17us/sample - loss: 38521613.4357\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.9677 - val_loss: 0.5279\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.9057 - val_loss: 0.6446\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7033 - val_loss: 3.6425\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 3.1071 - val_loss: 41.9776\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 921.7053 - val_loss: 533.6771\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 9929.6476 - val_loss: 5442.1672\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 3863.0575 - val_loss: 57784.9224\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 48780.3376 - val_loss: 649057.9059\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 469794.5275 - val_loss: 7063701.3309\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 5026826.7547 - val_loss: 76336107.7466\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 1778849049.4405 - val_loss: 865228133.9659\n",
      "3870/3870 [==============================] - 0s 18us/sample - loss: 12918986.9031\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 2.6044 - val_loss: 1.8381\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 1.5466 - val_loss: 1.4383\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 1.2333 - val_loss: 1.2440\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 1.0723 - val_loss: 1.1345\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.9780 - val_loss: 1.0575\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.9186 - val_loss: 1.0049\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.8785 - val_loss: 0.9616\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.8477 - val_loss: 0.9248\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.8217 - val_loss: 0.8912\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.7988 - val_loss: 0.8620\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.7782 - val_loss: 0.8339\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.7591 - val_loss: 0.8089\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.7414 - val_loss: 0.7864\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.7255 - val_loss: 0.7632\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.7110 - val_loss: 0.7434\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6971 - val_loss: 0.7249\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6840 - val_loss: 0.7075\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6719 - val_loss: 0.6925\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6609 - val_loss: 0.6767\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6503 - val_loss: 0.6628\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6402 - val_loss: 0.6499\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.6310 - val_loss: 0.6391\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6225 - val_loss: 0.6274\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6146 - val_loss: 0.6176\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6071 - val_loss: 0.6096\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6003 - val_loss: 0.6005\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5938 - val_loss: 0.5922\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5876 - val_loss: 0.5850\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5819 - val_loss: 0.5788\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5765 - val_loss: 0.5731\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5714 - val_loss: 0.5661\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5668 - val_loss: 0.5610\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5622 - val_loss: 0.5565\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5580 - val_loss: 0.5522\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5540 - val_loss: 0.5480\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5503 - val_loss: 0.5441\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5468 - val_loss: 0.5405\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5435 - val_loss: 0.5374\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5403 - val_loss: 0.5346\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5373 - val_loss: 0.5327\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5345 - val_loss: 0.5294\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5319 - val_loss: 0.5273\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5293 - val_loss: 0.5246\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5270 - val_loss: 0.5235\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5243 - val_loss: 0.5204\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5227 - val_loss: 0.5192\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5206 - val_loss: 0.5178\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5185 - val_loss: 0.5159\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5166 - val_loss: 0.5154\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5147 - val_loss: 0.5139\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5131 - val_loss: 0.5118\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5113 - val_loss: 0.5103\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5096 - val_loss: 0.5102\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5080 - val_loss: 0.5079\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5066 - val_loss: 0.5073\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5051 - val_loss: 0.5066\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5035 - val_loss: 0.5058\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5020 - val_loss: 0.5058\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5012 - val_loss: 0.5044\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4997 - val_loss: 0.5031\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4984 - val_loss: 0.5024\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4973 - val_loss: 0.5020\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4960 - val_loss: 0.5023\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4950 - val_loss: 0.5008\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4939 - val_loss: 0.5004\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4928 - val_loss: 0.4992\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4919 - val_loss: 0.4990\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4910 - val_loss: 0.4986\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4900 - val_loss: 0.4984\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4891 - val_loss: 0.4983\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4884 - val_loss: 0.4977\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4875 - val_loss: 0.4975\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4866 - val_loss: 0.4969\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4860 - val_loss: 0.4961\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4852 - val_loss: 0.4952\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4847 - val_loss: 0.4949\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4839 - val_loss: 0.4942\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4832 - val_loss: 0.4941\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4828 - val_loss: 0.4936\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4821 - val_loss: 0.4942\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4812 - val_loss: 0.4933\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4810 - val_loss: 0.4933\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4798 - val_loss: 0.4936\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4800 - val_loss: 0.4932\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4789 - val_loss: 0.4925\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4786 - val_loss: 0.4911\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4781 - val_loss: 0.4911\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4776 - val_loss: 0.4905\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4769 - val_loss: 0.4915\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4766 - val_loss: 0.4909\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4760 - val_loss: 0.4900\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4754 - val_loss: 0.4893\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4751 - val_loss: 0.4889\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4746 - val_loss: 0.4883\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4741 - val_loss: 0.4879\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4737 - val_loss: 0.4877\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4732 - val_loss: 0.4879\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4723 - val_loss: 0.4884\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4726 - val_loss: 0.4874\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4719 - val_loss: 0.4881\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.6621\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 3.2204 - val_loss: 2.3540\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 2.0740 - val_loss: 1.7075\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 1.5641 - val_loss: 1.3526\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 1.2733 - val_loss: 1.1356\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 1.1016 - val_loss: 1.0041\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.9951 - val_loss: 0.9178\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.9236 - val_loss: 0.8576\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.8703 - val_loss: 0.8120\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.8270 - val_loss: 0.7744\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7910 - val_loss: 0.7428\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.7588 - val_loss: 0.7135\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.7305 - val_loss: 0.6883\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.7053 - val_loss: 0.6668\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6834 - val_loss: 0.6469\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6646 - val_loss: 0.6304\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6487 - val_loss: 0.6176\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6357 - val_loss: 0.6046\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6252 - val_loss: 0.5949\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6161 - val_loss: 0.5861\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6078 - val_loss: 0.5785\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6003 - val_loss: 0.5712\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5935 - val_loss: 0.5647\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5871 - val_loss: 0.5592\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5811 - val_loss: 0.5532\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5755 - val_loss: 0.5486\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5700 - val_loss: 0.5429\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5650 - val_loss: 0.5381\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5603 - val_loss: 0.5338\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5561 - val_loss: 0.5301\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5516 - val_loss: 0.5269\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5480 - val_loss: 0.5226\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5441 - val_loss: 0.5192\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5403 - val_loss: 0.5154\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5369 - val_loss: 0.5121\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5333 - val_loss: 0.5088\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5302 - val_loss: 0.5071\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5269 - val_loss: 0.5038\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5239 - val_loss: 0.5007\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5207 - val_loss: 0.4990\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5184 - val_loss: 0.4959\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5154 - val_loss: 0.4933\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5129 - val_loss: 0.4912\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5103 - val_loss: 0.4881\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5078 - val_loss: 0.4858\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5060 - val_loss: 0.4846\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5037 - val_loss: 0.4824\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5017 - val_loss: 0.4807\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4996 - val_loss: 0.4787\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4977 - val_loss: 0.4772\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4959 - val_loss: 0.4758\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4940 - val_loss: 0.4739\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4921 - val_loss: 0.4720\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4903 - val_loss: 0.4702\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4896 - val_loss: 0.4696\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4875 - val_loss: 0.4675\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4857 - val_loss: 0.4653\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4842 - val_loss: 0.4644\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4835 - val_loss: 0.4632\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4816 - val_loss: 0.4617\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4799 - val_loss: 0.4595\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4791 - val_loss: 0.4596\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4777 - val_loss: 0.4581\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4763 - val_loss: 0.4576\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4749 - val_loss: 0.4570\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4742 - val_loss: 0.4556\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4728 - val_loss: 0.4547\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4716 - val_loss: 0.4532\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4705 - val_loss: 0.4518\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4698 - val_loss: 0.4513\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4687 - val_loss: 0.4499\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4675 - val_loss: 0.4489\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4665 - val_loss: 0.4474\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4654 - val_loss: 0.4478\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4649 - val_loss: 0.4464\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4639 - val_loss: 0.4465\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4630 - val_loss: 0.4440\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4620 - val_loss: 0.4428\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4612 - val_loss: 0.4423\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4606 - val_loss: 0.4421\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4599 - val_loss: 0.4405\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4589 - val_loss: 0.4411\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4582 - val_loss: 0.4396\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4573 - val_loss: 0.4384\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4570 - val_loss: 0.4385\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4561 - val_loss: 0.4377\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4553 - val_loss: 0.4371\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4545 - val_loss: 0.4356\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4541 - val_loss: 0.4354\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4532 - val_loss: 0.4343\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4526 - val_loss: 0.4341\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4519 - val_loss: 0.4329\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4515 - val_loss: 0.4336\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4508 - val_loss: 0.4333\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4498 - val_loss: 0.4305\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4496 - val_loss: 0.4304\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4490 - val_loss: 0.4307\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4486 - val_loss: 0.4296\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4479 - val_loss: 0.4296\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4474 - val_loss: 0.4288\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4467 - val_loss: 0.4279\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.4723\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 3.5597 - val_loss: 2.1850\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 1.5712 - val_loss: 1.0191\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.8662 - val_loss: 0.7085\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.7018 - val_loss: 0.6318\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6583 - val_loss: 0.6072\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6383 - val_loss: 0.5944\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6269 - val_loss: 0.5832\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6185 - val_loss: 0.5755\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6113 - val_loss: 0.5697\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6047 - val_loss: 0.5649\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5995 - val_loss: 0.5574\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5942 - val_loss: 0.5517\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5894 - val_loss: 0.5483\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5851 - val_loss: 0.5428\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5812 - val_loss: 0.5390\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5774 - val_loss: 0.5360\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5737 - val_loss: 0.5329\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5705 - val_loss: 0.5290\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5673 - val_loss: 0.5254\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5642 - val_loss: 0.5244\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5614 - val_loss: 0.5214\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5585 - val_loss: 0.5179\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5563 - val_loss: 0.5154\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5534 - val_loss: 0.5144\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5511 - val_loss: 0.5113\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5489 - val_loss: 0.5094\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5466 - val_loss: 0.5075\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5446 - val_loss: 0.5060\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5426 - val_loss: 0.5039\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5408 - val_loss: 0.5024\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5387 - val_loss: 0.5020\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5369 - val_loss: 0.4996\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5354 - val_loss: 0.4981\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5337 - val_loss: 0.4974\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5321 - val_loss: 0.4950\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5309 - val_loss: 0.4947\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5295 - val_loss: 0.4935\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5282 - val_loss: 0.4926\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5266 - val_loss: 0.4906\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5257 - val_loss: 0.4898\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5245 - val_loss: 0.4884\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5235 - val_loss: 0.4878\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5221 - val_loss: 0.4880\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5214 - val_loss: 0.4861\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5203 - val_loss: 0.4851\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5195 - val_loss: 0.4864\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5188 - val_loss: 0.4845\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5177 - val_loss: 0.4831\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5167 - val_loss: 0.4823\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5162 - val_loss: 0.4819\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5154 - val_loss: 0.4815\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5144 - val_loss: 0.4796\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5137 - val_loss: 0.4800\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5130 - val_loss: 0.4784\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5121 - val_loss: 0.4794\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5116 - val_loss: 0.4773\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5108 - val_loss: 0.4781\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5102 - val_loss: 0.4792\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5099 - val_loss: 0.4766\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5091 - val_loss: 0.4755\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5086 - val_loss: 0.4765\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5080 - val_loss: 0.4747\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5077 - val_loss: 0.4756\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5069 - val_loss: 0.4747\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5066 - val_loss: 0.4734\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5060 - val_loss: 0.4737\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5057 - val_loss: 0.4726\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5049 - val_loss: 0.4733\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5046 - val_loss: 0.4711\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5037 - val_loss: 0.4730\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5032 - val_loss: 0.4725\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5029 - val_loss: 0.4699\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5024 - val_loss: 0.4695\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5020 - val_loss: 0.4702\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5015 - val_loss: 0.4705\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5009 - val_loss: 0.4692\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5003 - val_loss: 0.4692\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5001 - val_loss: 0.4681\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4996 - val_loss: 0.4660\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4989 - val_loss: 0.4672\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4987 - val_loss: 0.4669\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4979 - val_loss: 0.4675\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4976 - val_loss: 0.4663\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4971 - val_loss: 0.4639\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4964 - val_loss: 0.4635\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4959 - val_loss: 0.4641\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4953 - val_loss: 0.4632\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4941 - val_loss: 0.4616\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4930 - val_loss: 0.4618\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4921 - val_loss: 0.4615\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4911 - val_loss: 0.4590\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4900 - val_loss: 0.4580\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4895 - val_loss: 0.4582\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4885 - val_loss: 0.4570\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4877 - val_loss: 0.4567\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4868 - val_loss: 0.4552\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4864 - val_loss: 0.4556\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4857 - val_loss: 0.4545\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4852 - val_loss: 0.4548\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4845 - val_loss: 0.4535\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.4956\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 1.8424 - val_loss: 0.7912\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.7215 - val_loss: 0.6841\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6649 - val_loss: 0.6309\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6296 - val_loss: 0.5892\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6009 - val_loss: 0.5580\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5760 - val_loss: 0.5338\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5575 - val_loss: 0.5121\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5416 - val_loss: 0.4968\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5275 - val_loss: 0.4850\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5181 - val_loss: 0.4756\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5092 - val_loss: 0.4722\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5020 - val_loss: 0.4710\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4943 - val_loss: 0.4643\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4905 - val_loss: 0.4645\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4852 - val_loss: 0.4647\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4811 - val_loss: 0.4670\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4774 - val_loss: 0.4700\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4730 - val_loss: 0.4682\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4687 - val_loss: 0.4724\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4653 - val_loss: 0.4726\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4649 - val_loss: 0.4774\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4602 - val_loss: 0.4793\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4576 - val_loss: 0.4842\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.7225\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 81us/sample - loss: 1.8009 - val_loss: 0.8410\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.8990 - val_loss: 0.6663\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.7125 - val_loss: 0.5982\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6107 - val_loss: 0.5473\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5759 - val_loss: 0.5227\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5470 - val_loss: 0.5043\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5286 - val_loss: 0.4877\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5100 - val_loss: 0.4728\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5013 - val_loss: 0.4640\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4908 - val_loss: 0.4596\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4799 - val_loss: 0.4520\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4790 - val_loss: 0.4439\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4690 - val_loss: 0.4416\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4664 - val_loss: 0.4441\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4605 - val_loss: 0.4325\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4582 - val_loss: 0.4290\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4529 - val_loss: 0.4262\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4513 - val_loss: 0.4252\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4477 - val_loss: 0.4240\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4453 - val_loss: 0.4223\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4454 - val_loss: 0.4201\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4421 - val_loss: 0.4179\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4479 - val_loss: 0.4189\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4472 - val_loss: 0.4135\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4362 - val_loss: 0.4115\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4320 - val_loss: 0.4101\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4307 - val_loss: 0.4108\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4316 - val_loss: 0.4113\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4331 - val_loss: 0.4122\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4279 - val_loss: 0.4074\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4301 - val_loss: 0.4106\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4351 - val_loss: 0.4039\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4227 - val_loss: 0.4027\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4240 - val_loss: 0.4022\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4183 - val_loss: 0.4023\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4183 - val_loss: 0.3998\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4175 - val_loss: 0.3990\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4195 - val_loss: 0.3988\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - ETA: 0s - loss: 0.415 - 0s 39us/sample - loss: 0.4142 - val_loss: 0.3957\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4140 - val_loss: 0.3978\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4144 - val_loss: 0.3997\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4144 - val_loss: 0.3959\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4110 - val_loss: 0.3936\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4107 - val_loss: 0.3924\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4073 - val_loss: 0.3898\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4072 - val_loss: 0.3924\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4060 - val_loss: 0.3905\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4072 - val_loss: 0.3917\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4077 - val_loss: 0.3918\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4051 - val_loss: 0.3887\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4020 - val_loss: 0.3870\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4022 - val_loss: 0.3862\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4010 - val_loss: 0.3873\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4064 - val_loss: 0.3899\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4039 - val_loss: 0.3884\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4120 - val_loss: 0.3915\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4075 - val_loss: 0.3940\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4340 - val_loss: 0.3959\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4146 - val_loss: 0.3916\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4091 - val_loss: 0.3853\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4031 - val_loss: 0.3813\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3937 - val_loss: 0.3803\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3947 - val_loss: 0.3785\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3918 - val_loss: 0.3781\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3918 - val_loss: 0.3778\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3904 - val_loss: 0.3771\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3903 - val_loss: 0.3770\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3893 - val_loss: 0.3757\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3885 - val_loss: 0.3765\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3893 - val_loss: 0.3759\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3890 - val_loss: 0.3758\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3868 - val_loss: 0.3755\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3874 - val_loss: 0.3758\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3877 - val_loss: 0.3812\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3908 - val_loss: 0.3752\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3953 - val_loss: 0.3730\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3837 - val_loss: 0.3719\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3825 - val_loss: 0.3729\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3831 - val_loss: 0.3737\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3807 - val_loss: 0.3713\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3814 - val_loss: 0.3718\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3810 - val_loss: 0.3691\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3799 - val_loss: 0.3681\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3780 - val_loss: 0.3723\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3820 - val_loss: 0.3687\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3781 - val_loss: 0.3764\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3853 - val_loss: 0.3683\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3764 - val_loss: 0.3713\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3791 - val_loss: 0.3674\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3754 - val_loss: 0.3686\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3757 - val_loss: 0.3665\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3739 - val_loss: 0.3746\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3982 - val_loss: 0.3656\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3724 - val_loss: 0.3666\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3732 - val_loss: 0.3642\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3708 - val_loss: 0.3643\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3720 - val_loss: 0.3687\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3752 - val_loss: 0.3692\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3834 - val_loss: 0.3650\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3707 - val_loss: 0.3620\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3998\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 1.7366 - val_loss: 0.9236\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.8888 - val_loss: 0.7115\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.7059 - val_loss: 0.6367\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6445 - val_loss: 0.5982\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6066 - val_loss: 0.5679\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5802 - val_loss: 0.5434\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5590 - val_loss: 0.5272\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5426 - val_loss: 0.5087\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5284 - val_loss: 0.4975\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5169 - val_loss: 0.4858\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5093 - val_loss: 0.4805\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5016 - val_loss: 0.4728\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4960 - val_loss: 0.4661\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4902 - val_loss: 0.4631\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4865 - val_loss: 0.4582\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4826 - val_loss: 0.4563\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4789 - val_loss: 0.4507\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4754 - val_loss: 0.4475\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4724 - val_loss: 0.4453\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4696 - val_loss: 0.4455\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4680 - val_loss: 0.4399\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4645 - val_loss: 0.4392\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4626 - val_loss: 0.4371\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4602 - val_loss: 0.4339\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4585 - val_loss: 0.4326\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4558 - val_loss: 0.4313\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4540 - val_loss: 0.4285\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4520 - val_loss: 0.4271\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4501 - val_loss: 0.4265\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4485 - val_loss: 0.4240\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4468 - val_loss: 0.4256\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4450 - val_loss: 0.4207\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4444 - val_loss: 0.4205\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4426 - val_loss: 0.4183\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4416 - val_loss: 0.4182\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4394 - val_loss: 0.4164\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4383 - val_loss: 0.4154\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4372 - val_loss: 0.4139\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4355 - val_loss: 0.4133\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4345 - val_loss: 0.4117\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4332 - val_loss: 0.4131\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4322 - val_loss: 0.4140\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4325 - val_loss: 0.4098\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4296 - val_loss: 0.4081\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4288 - val_loss: 0.4071\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4274 - val_loss: 0.4069\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4269 - val_loss: 0.4067\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4248 - val_loss: 0.4040\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4245 - val_loss: 0.4023\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4234 - val_loss: 0.4016\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4225 - val_loss: 0.4008\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4214 - val_loss: 0.4008\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4198 - val_loss: 0.3982\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4188 - val_loss: 0.3979\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4178 - val_loss: 0.3967\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4169 - val_loss: 0.3958\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4154 - val_loss: 0.3955\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4155 - val_loss: 0.3940\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4134 - val_loss: 0.3929\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4126 - val_loss: 0.3940\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4114 - val_loss: 0.3931\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4113 - val_loss: 0.3902\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4093 - val_loss: 0.3898\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4089 - val_loss: 0.3898\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4082 - val_loss: 0.3876\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4078 - val_loss: 0.3865\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4062 - val_loss: 0.3862\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4050 - val_loss: 0.3868\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4043 - val_loss: 0.3844\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4037 - val_loss: 0.3844\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4026 - val_loss: 0.3831\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4017 - val_loss: 0.3825\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4008 - val_loss: 0.3822\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3997 - val_loss: 0.3821\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3997 - val_loss: 0.3817\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3985 - val_loss: 0.3805\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3975 - val_loss: 0.3789\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3963 - val_loss: 0.3787\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3961 - val_loss: 0.3794\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3947 - val_loss: 0.3770\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3942 - val_loss: 0.3781\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3934 - val_loss: 0.3769\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3926 - val_loss: 0.3765\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3918 - val_loss: 0.3754\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3913 - val_loss: 0.3752\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3905 - val_loss: 0.3757\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3897 - val_loss: 0.3740\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3900 - val_loss: 0.3732\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3880 - val_loss: 0.3722\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3878 - val_loss: 0.3711\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3866 - val_loss: 0.3731\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3866 - val_loss: 0.3707\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3849 - val_loss: 0.3700\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3845 - val_loss: 0.3712\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3848 - val_loss: 0.3700\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3841 - val_loss: 0.3696\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3834 - val_loss: 0.3707\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3821 - val_loss: 0.3699\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3817 - val_loss: 0.3681\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3826 - val_loss: 0.3672\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3863\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 5.0839 - val_loss: 3.4774\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 2.6641 - val_loss: 2.0162\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 1.6355 - val_loss: 1.3652\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 1.1746 - val_loss: 1.0662\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.9603 - val_loss: 0.9236\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.8561 - val_loss: 0.8512\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.8014 - val_loss: 0.8101\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7699 - val_loss: 0.7838\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7491 - val_loss: 0.7642\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7339 - val_loss: 0.7483\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7213 - val_loss: 0.7343\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7105 - val_loss: 0.7216\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7008 - val_loss: 0.7096\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6918 - val_loss: 0.6982\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6837 - val_loss: 0.6876\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6760 - val_loss: 0.6775\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6687 - val_loss: 0.6680\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6620 - val_loss: 0.6589\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6556 - val_loss: 0.6502\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6496 - val_loss: 0.6420\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6440 - val_loss: 0.6342\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6387 - val_loss: 0.6269\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6338 - val_loss: 0.6199\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6291 - val_loss: 0.6131\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6247 - val_loss: 0.6069\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6204 - val_loss: 0.6008\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6166 - val_loss: 0.5950\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6129 - val_loss: 0.5896\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6093 - val_loss: 0.5842\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6062 - val_loss: 0.5795\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6030 - val_loss: 0.5748\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6000 - val_loss: 0.5702\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5972 - val_loss: 0.5659\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5947 - val_loss: 0.5621\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5922 - val_loss: 0.5584\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5896 - val_loss: 0.5544\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5874 - val_loss: 0.5509\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5856 - val_loss: 0.5480\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5835 - val_loss: 0.5451\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5815 - val_loss: 0.5420\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5797 - val_loss: 0.5390\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5781 - val_loss: 0.5367\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5764 - val_loss: 0.5343\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5748 - val_loss: 0.5324\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5731 - val_loss: 0.5295\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5717 - val_loss: 0.5271\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5706 - val_loss: 0.5252\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5692 - val_loss: 0.5234\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5681 - val_loss: 0.5222\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5669 - val_loss: 0.5207\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5658 - val_loss: 0.5190\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5645 - val_loss: 0.5171\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5637 - val_loss: 0.5159\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5627 - val_loss: 0.5146\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5615 - val_loss: 0.5133\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5609 - val_loss: 0.5131\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5599 - val_loss: 0.5116\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5593 - val_loss: 0.5111\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5579 - val_loss: 0.5094\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5578 - val_loss: 0.5092\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5569 - val_loss: 0.5092\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5562 - val_loss: 0.5086\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5556 - val_loss: 0.5084\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5545 - val_loss: 0.5069\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5543 - val_loss: 0.5072\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5534 - val_loss: 0.5063\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5530 - val_loss: 0.5059\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5522 - val_loss: 0.5055\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5518 - val_loss: 0.5062\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5510 - val_loss: 0.5054\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5510 - val_loss: 0.5059\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5500 - val_loss: 0.5054\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5500 - val_loss: 0.5059\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5495 - val_loss: 0.5060\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5491 - val_loss: 0.5062\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5486 - val_loss: 0.5074\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5481 - val_loss: 0.5080\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5477 - val_loss: 0.5074\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5473 - val_loss: 0.5075\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5466 - val_loss: 0.5076\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.5596\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 5.4615 - val_loss: 3.1868\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 2.5215 - val_loss: 1.6703\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 1.4178 - val_loss: 1.0413\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.9628 - val_loss: 0.7700\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.7647 - val_loss: 0.6504\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6750 - val_loss: 0.5965\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6320 - val_loss: 0.5707\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6100 - val_loss: 0.5575\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5975 - val_loss: 0.5499\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5898 - val_loss: 0.5450\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5843 - val_loss: 0.5413\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5800 - val_loss: 0.5384\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5764 - val_loss: 0.5358\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5733 - val_loss: 0.5333\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5705 - val_loss: 0.5311\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5678 - val_loss: 0.5291\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5655 - val_loss: 0.5271\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5632 - val_loss: 0.5252\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5611 - val_loss: 0.5236\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5592 - val_loss: 0.5221\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5574 - val_loss: 0.5204\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5557 - val_loss: 0.5190\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5542 - val_loss: 0.5176\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5527 - val_loss: 0.5167\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5514 - val_loss: 0.5157\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5502 - val_loss: 0.5148\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5489 - val_loss: 0.5141\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5479 - val_loss: 0.5128\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5468 - val_loss: 0.5122\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5458 - val_loss: 0.5116\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5448 - val_loss: 0.5103\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5439 - val_loss: 0.5093\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5431 - val_loss: 0.5085\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5426 - val_loss: 0.5084\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5417 - val_loss: 0.5076\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5411 - val_loss: 0.5079\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5405 - val_loss: 0.5073\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5400 - val_loss: 0.5068\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5392 - val_loss: 0.5058\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5388 - val_loss: 0.5052\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5385 - val_loss: 0.5056\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5380 - val_loss: 0.5048\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5377 - val_loss: 0.5048\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5371 - val_loss: 0.5042\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5368 - val_loss: 0.5037\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5366 - val_loss: 0.5042\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5359 - val_loss: 0.5031\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5357 - val_loss: 0.5027\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5358 - val_loss: 0.5033\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5354 - val_loss: 0.5037\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5351 - val_loss: 0.5033\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5349 - val_loss: 0.5029\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5348 - val_loss: 0.5028\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5344 - val_loss: 0.5021\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5343 - val_loss: 0.5023\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5340 - val_loss: 0.5018\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5339 - val_loss: 0.5014\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5337 - val_loss: 0.5011\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5337 - val_loss: 0.5010\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5337 - val_loss: 0.5012\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5335 - val_loss: 0.5013\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5335 - val_loss: 0.5016\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5332 - val_loss: 0.5024\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5331 - val_loss: 0.5018\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5329 - val_loss: 0.5023\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5329 - val_loss: 0.5018\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5328 - val_loss: 0.5022\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5327 - val_loss: 0.5015\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5324 - val_loss: 0.5009\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5326 - val_loss: 0.5009\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5324 - val_loss: 0.5007\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5323 - val_loss: 0.5004\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5325 - val_loss: 0.5006\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5324 - val_loss: 0.5016\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5321 - val_loss: 0.5008\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5323 - val_loss: 0.5015\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5321 - val_loss: 0.5017\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5322 - val_loss: 0.5016\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5321 - val_loss: 0.5015\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5316 - val_loss: 0.5005\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5321 - val_loss: 0.5008\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5319 - val_loss: 0.5015\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.5522\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 5.2286 - val_loss: 3.4533\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 2.6488 - val_loss: 1.8688\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 1.5714 - val_loss: 1.1882\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 1.0955 - val_loss: 0.8829\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.8736 - val_loss: 0.7390\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.7651 - val_loss: 0.6683\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7088 - val_loss: 0.6308\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6774 - val_loss: 0.6095\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6584 - val_loss: 0.5959\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6455 - val_loss: 0.5861\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6359 - val_loss: 0.5787\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6282 - val_loss: 0.5726\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6218 - val_loss: 0.5672\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6161 - val_loss: 0.5623\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6109 - val_loss: 0.5580\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6062 - val_loss: 0.5539\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6017 - val_loss: 0.5502\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5977 - val_loss: 0.5467\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5939 - val_loss: 0.5434\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5903 - val_loss: 0.5403\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5869 - val_loss: 0.5374\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5838 - val_loss: 0.5348\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5808 - val_loss: 0.5324\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5780 - val_loss: 0.5301\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5753 - val_loss: 0.5279\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5729 - val_loss: 0.5259\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5706 - val_loss: 0.5240\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5683 - val_loss: 0.5222\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5663 - val_loss: 0.5205\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5644 - val_loss: 0.5190\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5625 - val_loss: 0.5176\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5608 - val_loss: 0.5162\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5592 - val_loss: 0.5149\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5577 - val_loss: 0.5138\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5562 - val_loss: 0.5126\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5549 - val_loss: 0.5116\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5536 - val_loss: 0.5106\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5524 - val_loss: 0.5097\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5513 - val_loss: 0.5089\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5502 - val_loss: 0.5081\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5492 - val_loss: 0.5074\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5483 - val_loss: 0.5066\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5474 - val_loss: 0.5060\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5466 - val_loss: 0.5054\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5458 - val_loss: 0.5049\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5451 - val_loss: 0.5044\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5443 - val_loss: 0.5040\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5437 - val_loss: 0.5036\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5430 - val_loss: 0.5031\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5425 - val_loss: 0.5027\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5420 - val_loss: 0.5023\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5414 - val_loss: 0.5019\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5410 - val_loss: 0.5016\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5405 - val_loss: 0.5013\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5401 - val_loss: 0.5011\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5397 - val_loss: 0.5009\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5392 - val_loss: 0.5006\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5389 - val_loss: 0.5005\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5386 - val_loss: 0.5003\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5383 - val_loss: 0.5001\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5380 - val_loss: 0.4999\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5377 - val_loss: 0.4998\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5374 - val_loss: 0.4996\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5371 - val_loss: 0.4995\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5369 - val_loss: 0.4993\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5367 - val_loss: 0.4992\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5365 - val_loss: 0.4991\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5363 - val_loss: 0.4991\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5361 - val_loss: 0.4990\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5359 - val_loss: 0.4989\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5357 - val_loss: 0.4989\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5356 - val_loss: 0.4988\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5354 - val_loss: 0.4988\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5353 - val_loss: 0.4987\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5352 - val_loss: 0.4987\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5350 - val_loss: 0.4986\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5349 - val_loss: 0.4986\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5348 - val_loss: 0.4985\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5347 - val_loss: 0.4985\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5346 - val_loss: 0.4985\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5345 - val_loss: 0.4985\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5344 - val_loss: 0.4985\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5343 - val_loss: 0.4985\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5342 - val_loss: 0.4984\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5342 - val_loss: 0.4985\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5341 - val_loss: 0.4985\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5341 - val_loss: 0.4984\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5340 - val_loss: 0.4984\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5339 - val_loss: 0.4984\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5339 - val_loss: 0.4984\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5338 - val_loss: 0.4984\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5337 - val_loss: 0.4985\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5337 - val_loss: 0.4984\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5337 - val_loss: 0.4984\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5337 - val_loss: 0.4984\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5336 - val_loss: 0.4985\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5336 - val_loss: 0.4984\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5336 - val_loss: 0.4984\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5335 - val_loss: 0.4983\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5335 - val_loss: 0.4983\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.5548\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002246E8DD208>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-5400e098aba9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m rnd_search_cv.fit(X_train, y_train, epochs=100,\n\u001b[0;32m      9\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files\\Anaconda\\envs\\ML_book_OR\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda\\envs\\ML_book_OR\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[1;32m--> 762\u001b[1;33m                 **self.best_params_))\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda\\envs\\ML_book_OR\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda\\envs\\ML_book_OR\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     96\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0;32m     97\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                                (estimator, name))\n\u001b[0m\u001b[0;32m     99\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002246E8DD208>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "    }\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10,\n",
    "cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "validation_data=(X_valid, y_valid),\n",
    "callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it’s over, you can access the best parameters found, the best\n",
    "score, and the trained Keras model like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.32856573809794987"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_\n",
    "{'learning_rate': 0.0033625641252688094, 'n_hidden': 2, 'n_neurons': 42}\n",
    "rnd_search_cv.best_score_\n",
    "#-0.3189529188278931\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-87283a9b864c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
