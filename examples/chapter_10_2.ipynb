{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Regression MLP Using the Sequential API\n",
    "Let’s switch to the California housing problem and tackle it using a\n",
    "regression neural network.   \n",
    "After loading the data, we split it into a training set, a\n",
    "validation set, and a test set, and we scale all the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train_full, y_train_full)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 1.0116 - val_loss: 0.6095\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - ETA: 0s - loss: 0.484 - 1s 44us/sample - loss: 0.4834 - val_loss: 0.4440\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4383 - val_loss: 0.4211\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4239 - val_loss: 0.4251\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4123 - val_loss: 0.4100\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.4030 - val_loss: 0.3933\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3973 - val_loss: 0.3829\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3947 - val_loss: 0.3785\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3920 - val_loss: 0.3772\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3871 - val_loss: 0.3729\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3877 - val_loss: 0.3734\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3808 - val_loss: 0.3735\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3829 - val_loss: 0.3717\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3760 - val_loss: 0.3677\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3726 - val_loss: 0.3630\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3694 - val_loss: 0.3625\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3800 - val_loss: 0.3567\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3662 - val_loss: 0.3737\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3667 - val_loss: 0.3562\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3666 - val_loss: 0.3521\n",
      "5160/5160 [==============================] - 0s 20us/sample - loss: 0.3794\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Dense(30, activation=\"relu\",\n",
    "input_shape=X_train.shape[1:]),\n",
    "keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the Sequential API is quite easy to use. However, although\n",
    "Sequential models are extremely common, it is sometimes useful to\n",
    "build neural networks with more complex topologies, or with multiple\n",
    "inputs or outputs. For this purpose, Keras offers the Functional API.\n",
    "\n",
    "\n",
    "# Building Complex Models Using the Functional API\n",
    "One example of a nonsequential neural network is a Wide & Deep neural\n",
    "network. This neural network architecture was introduced in a 2016 paper\n",
    "by Heng-Tze Cheng et al. It connects all or part of the inputs directly to\n",
    "the output layer,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s go through each line of this code:\n",
    "* First, we need to create an Input object. This is a specification\n",
    "of the kind of input the model will get, including its shape and\n",
    "dtype. A model may actually have multiple inputs, as we will see\n",
    "shortly.\n",
    "* Next, we create a Dense layer with 30 neurons, using the ReLU\n",
    "activation function. As soon as it is created, notice that we call it\n",
    "like a function, passing it the input. This is why this is called the\n",
    "Functional API. Note that we are just telling Keras how it should\n",
    "connect the layers together; no actual data is being processed yet.\n",
    "* We then create a second hidden layer, and again we use it as a\n",
    "function. Note that we pass it the output of the first hidden layer.\n",
    "* Next, we create a Concatenate layer, and once again we\n",
    "immediately use it like a function, to concatenate the input and\n",
    "the output of the second hidden layer. You may prefer the\n",
    "keras.layers.concatenate() function, which creates a\n",
    "Concatenate layer and immediately calls it with the given inputs.\n",
    "* Then we create the output layer, with a single neuron and no\n",
    "activation function, and we call it like a function, passing it the\n",
    "result of the concatenation.\n",
    "\n",
    "Lastly, we create a Keras Model, specifying which inputs and\n",
    "outputs to use.  \n",
    "If you want to send a subset of the features through the wide path\n",
    "and a different subset (possibly overlapping) through the deep path? In this case, one solution is to use multiple inputs. For\n",
    "example, suppose we want to send five features through the wide path\n",
    "(features 0 to 4), and six features through the deep path (features 2 to 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 2.0090 - val_loss: 0.9477\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.7577 - val_loss: 0.7546\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.6824 - val_loss: 0.6970\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.6386 - val_loss: 0.6536\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.6023 - val_loss: 0.6145\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.5726 - val_loss: 0.5806\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.5463 - val_loss: 0.5525\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.5261 - val_loss: 0.5316\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.5106 - val_loss: 0.5258\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4996 - val_loss: 0.5136\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4911 - val_loss: 0.5077\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4842 - val_loss: 0.4967\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4767 - val_loss: 0.4789\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4703 - val_loss: 0.4822\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4659 - val_loss: 0.4757\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4611 - val_loss: 0.4689\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4561 - val_loss: 0.4662\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4524 - val_loss: 0.4525\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4487 - val_loss: 0.4581\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.4452 - val_loss: 0.4547\n",
      "5160/5160 [==============================] - 0s 22us/sample - loss: 0.4655\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
